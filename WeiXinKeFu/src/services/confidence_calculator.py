"""
é«˜çº§ç½®ä¿¡åº¦è®¡ç®—å¼•æ“
æä¾›å¤šå› ç´ ç»¼åˆè¯„åˆ†å’ŒåŠ¨æ€æƒé‡è°ƒæ•´æœºåˆ¶
"""

import json
import logging
import math
import re
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime
from difflib import SequenceMatcher

logger = logging.getLogger(__name__)

class AdvancedConfidenceCalculator:
    """é«˜çº§ç½®ä¿¡åº¦è®¡ç®—å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç½®ä¿¡åº¦è®¡ç®—å™¨"""
        # å­—æ®µé‡è¦æ€§æƒé‡é…ç½®
        self.field_weights = {
            'company': 0.35,        # å…¬å¸ä¿¡æ¯æƒé‡æœ€é«˜
            'education': 0.25,      # æ•™è‚²èƒŒæ™¯é‡è¦æ€§è¾ƒé«˜
            'location': 0.20,       # åœ°ç†ä½ç½®ä¸­ç­‰é‡è¦
            'position': 0.15,       # èŒä½ä¿¡æ¯è¡¥å……ä½œç”¨
            'phone': 0.30,          # ç”µè¯å·ç ç²¾ç¡®åŒ¹é…ä»·å€¼é«˜
            'email': 0.25,          # é‚®ç®±åŸŸåå¯æ˜¾ç¤ºå…³è”
            'industry': 0.20,       # è¡Œä¸šç›¸å…³æ€§
            'age_group': 0.10       # å¹´é¾„æ®µè¾…åŠ©åˆ¤æ–­
        }
        
        # å…³ç³»ç±»å‹ç½®ä¿¡åº¦åŸºå‡†
        self.relationship_baselines = {
            'colleague': {'base': 0.4, 'company_boost': 0.4, 'location_boost': 0.1},
            'friend': {'base': 0.3, 'location_boost': 0.3, 'education_boost': 0.2},
            'family': {'base': 0.2, 'phone_boost': 0.5, 'location_boost': 0.3},
            'partner': {'base': 0.3, 'company_boost': 0.3, 'industry_boost': 0.2},
            'client': {'base': 0.3, 'industry_boost': 0.3, 'position_boost': 0.2},
            'supplier': {'base': 0.3, 'industry_boost': 0.3, 'company_boost': 0.1},
            'alumni': {'base': 0.3, 'education_boost': 0.4, 'age_boost': 0.1},
            'neighbor': {'base': 0.2, 'location_boost': 0.5, 'phone_boost': 0.1},
            'same_location': {'base': 0.2, 'location_boost': 0.6},
            'competitor': {'base': 0.3, 'industry_boost': 0.3, 'position_boost': 0.2},
            'investor': {'base': 0.2, 'industry_boost': 0.4, 'company_boost': 0.2}
        }
        
        # åŒ¹é…æ–¹æ³•å¯é æ€§ç³»æ•°
        self.method_reliability = {
            'exact_match': 1.0,
            'fuzzy_match': 0.8,
            'semantic_match': 0.7,
            'partial_match': 0.6,
            'ai_inference': 0.9,
            'rule_based': 0.7,
            'pattern_match': 0.6
        }
        
    def calculate_comprehensive_confidence(
        self, 
        profile1: Dict, 
        profile2: Dict,
        relationship_type: str,
        evidence: Dict = None,
        method: str = 'ai_inference'
    ) -> Tuple[float, Dict[str, Any]]:
        """
        è®¡ç®—ç»¼åˆç½®ä¿¡åº¦åˆ†æ•°
        
        Args:
            profile1: æºè”ç³»äººèµ„æ–™
            profile2: ç›®æ ‡è”ç³»äººèµ„æ–™  
            relationship_type: å…³ç³»ç±»å‹
            evidence: æ”¯æŒè¯æ®
            method: åŒ¹é…æ–¹æ³•
        
        Returns:
            (ç½®ä¿¡åº¦åˆ†æ•°, è¯¦ç»†åˆ†æç»“æœ)
        """
        try:
            logger.info(f"ğŸ§® å¼€å§‹è®¡ç®—ç½®ä¿¡åº¦ - å…³ç³»ç±»å‹: {relationship_type}, æ–¹æ³•: {method}")
            
            # 1. å­—æ®µåŒ¹é…åˆ†æ
            field_scores = self._analyze_field_matches(profile1, profile2)
            
            # 2. å…³ç³»ç±»å‹é€‚é…æ€§è¯„ä¼°
            type_score = self._calculate_type_compatibility(profile1, profile2, relationship_type)
            
            # 3. è¯æ®å¼ºåº¦è¯„ä¼°
            evidence_score = self._evaluate_evidence_strength(evidence or {})
            
            # 4. æ–¹æ³•å¯é æ€§è°ƒæ•´
            method_factor = self.method_reliability.get(method, 0.7)
            
            # 5. ç»¼åˆç½®ä¿¡åº¦è®¡ç®—
            final_confidence, breakdown = self._compute_final_confidence(
                field_scores, type_score, evidence_score, method_factor, relationship_type
            )
            
            # 6. ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š
            analysis_report = {
                'final_confidence': final_confidence,
                'confidence_breakdown': breakdown,
                'field_analysis': field_scores,
                'type_compatibility': type_score,
                'evidence_strength': evidence_score,
                'method_reliability': method_factor,
                'quality_indicators': self._generate_quality_indicators(final_confidence, breakdown),
                'improvement_suggestions': self._suggest_improvements(field_scores, evidence_score),
                'calculation_timestamp': datetime.now().isoformat()
            }
            
            logger.info(f"âœ… ç½®ä¿¡åº¦è®¡ç®—å®Œæˆ - æœ€ç»ˆåˆ†æ•°: {final_confidence:.3f}")
            return final_confidence, analysis_report
            
        except Exception as e:
            logger.error(f"âŒ ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.5, {'error': str(e), 'fallback_confidence': 0.5}
    
    def _analyze_field_matches(self, profile1: Dict, profile2: Dict) -> Dict[str, Dict]:
        """åˆ†æå­—æ®µåŒ¹é…æƒ…å†µ"""
        field_analysis = {}
        
        # å…¬å¸åŒ¹é…åˆ†æ
        company_result = self._analyze_company_match(
            profile1.get('company', ''), 
            profile2.get('company', '')
        )
        if company_result['score'] > 0:
            field_analysis['company'] = company_result
        
        # æ•™è‚²èƒŒæ™¯åŒ¹é…
        education_result = self._analyze_education_match(
            profile1.get('education', ''),
            profile2.get('education', '')
        )
        if education_result['score'] > 0:
            field_analysis['education'] = education_result
        
        # åœ°ç†ä½ç½®åŒ¹é…
        location_result = self._analyze_location_match(
            profile1.get('location', profile1.get('address', '')),
            profile2.get('location', profile2.get('address', ''))
        )
        if location_result['score'] > 0:
            field_analysis['location'] = location_result
        
        # è”ç³»æ–¹å¼åŒ¹é…
        contact_result = self._analyze_contact_match(profile1, profile2)
        if contact_result['score'] > 0:
            field_analysis['contact'] = contact_result
        
        # èŒä½äº’è¡¥æ€§åˆ†æ
        position_result = self._analyze_position_relationship(
            profile1.get('position', ''),
            profile2.get('position', '')
        )
        if position_result['score'] > 0:
            field_analysis['position'] = position_result
        
        return field_analysis
    
    def _analyze_company_match(self, company1: str, company2: str) -> Dict:
        """å…¬å¸åŒ¹é…åˆ†æ"""
        if not company1 or not company2 or company1 == 'æœªçŸ¥' or company2 == 'æœªçŸ¥':
            return {'score': 0, 'type': 'no_data', 'explanation': 'ç¼ºå°‘å…¬å¸ä¿¡æ¯'}
        
        # ç²¾ç¡®åŒ¹é…
        if company1.strip().lower() == company2.strip().lower():
            return {
                'score': 1.0,
                'type': 'exact_match',
                'explanation': f'å…¬å¸å®Œå…¨åŒ¹é…: {company1}'
            }
        
        # è®¡ç®—é«˜çº§ç›¸ä¼¼åº¦
        similarity = self._calculate_advanced_similarity(company1, company2)
        
        if similarity > 0.9:
            return {
                'score': 0.95,
                'type': 'near_exact',
                'explanation': f'å…¬å¸é«˜åº¦ç›¸ä¼¼: {company1} â‰ˆ {company2}',
                'similarity': similarity
            }
        elif similarity > 0.7:
            return {
                'score': 0.8,
                'type': 'fuzzy_match',
                'explanation': f'å…¬å¸ç›¸ä¼¼: {company1} ~ {company2}',
                'similarity': similarity
            }
        elif similarity > 0.4:
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ¯å­å…¬å¸æˆ–å…³è”å…¬å¸
            relation_score = self._check_company_relationship(company1, company2)
            if relation_score > 0:
                return {
                    'score': 0.6 + relation_score * 0.2,
                    'type': 'related_company',
                    'explanation': f'å¯èƒ½å­˜åœ¨å…¬å¸å…³è”: {company1} â†” {company2}',
                    'relation_confidence': relation_score
                }
        
        return {'score': 0, 'type': 'no_match', 'explanation': 'å…¬å¸ä¸åŒ¹é…'}
    
    def _analyze_education_match(self, edu1: str, edu2: str) -> Dict:
        """æ•™è‚²èƒŒæ™¯åŒ¹é…åˆ†æ"""
        if not edu1 or not edu2 or edu1 == 'æœªçŸ¥' or edu2 == 'æœªçŸ¥':
            return {'score': 0, 'type': 'no_data', 'explanation': 'ç¼ºå°‘æ•™è‚²ä¿¡æ¯'}
        
        # æå–å­¦æ ¡åç§°
        school1 = self._extract_school_name(edu1)
        school2 = self._extract_school_name(edu2)
        
        if school1 and school2:
            similarity = self._calculate_advanced_similarity(school1, school2)
            
            if similarity > 0.8:
                return {
                    'score': 0.9,
                    'type': 'same_school',
                    'explanation': f'åŒæ ¡æ ¡å‹: {school1}',
                    'similarity': similarity
                }
            elif similarity > 0.5:
                return {
                    'score': 0.6,
                    'type': 'related_school',
                    'explanation': f'ç›¸å…³é™¢æ ¡: {school1} ~ {school2}',
                    'similarity': similarity
                }
        
        return {'score': 0, 'type': 'no_match', 'explanation': 'æ•™è‚²èƒŒæ™¯ä¸åŒ¹é…'}
    
    def _analyze_location_match(self, loc1: str, loc2: str) -> Dict:
        """åœ°ç†ä½ç½®åŒ¹é…åˆ†æ"""
        if not loc1 or not loc2 or loc1 == 'æœªçŸ¥' or loc2 == 'æœªçŸ¥':
            return {'score': 0, 'type': 'no_data', 'explanation': 'ç¼ºå°‘ä½ç½®ä¿¡æ¯'}
        
        # å¤šå±‚çº§åœ°ç†åŒ¹é…
        city1, province1, country1 = self._parse_location(loc1)
        city2, province2, country2 = self._parse_location(loc2)
        
        if city1 and city2 and city1.lower() == city2.lower():
            return {
                'score': 0.9,
                'type': 'same_city',
                'explanation': f'åŒåŸ: {city1}'
            }
        elif province1 and province2 and province1.lower() == province2.lower():
            return {
                'score': 0.6,
                'type': 'same_province',
                'explanation': f'åŒçœ: {province1}'
            }
        elif country1 and country2 and country1.lower() == country2.lower():
            return {
                'score': 0.3,
                'type': 'same_country',
                'explanation': f'åŒå›½: {country1}'
            }
        
        return {'score': 0, 'type': 'no_match', 'explanation': 'åœ°ç†ä½ç½®ä¸åŒ¹é…'}
    
    def _analyze_contact_match(self, profile1: Dict, profile2: Dict) -> Dict:
        """è”ç³»æ–¹å¼åŒ¹é…åˆ†æ"""
        phone1 = profile1.get('phone', '').strip()
        phone2 = profile2.get('phone', '').strip()
        email1 = profile1.get('email', '').strip()
        email2 = profile2.get('email', '').strip()
        
        max_score = 0
        best_match = {'score': 0, 'type': 'no_match', 'explanation': 'è”ç³»æ–¹å¼ä¸åŒ¹é…'}
        
        # ç”µè¯å·ç åŒ¹é…
        if phone1 and phone2:
            phone_similarity = self._compare_phone_numbers(phone1, phone2)
            if phone_similarity > 0.8:
                best_match = {
                    'score': 0.95,
                    'type': 'phone_match',
                    'explanation': 'ç”µè¯å·ç åŒ¹é…',
                    'similarity': phone_similarity
                }
                max_score = 0.95
        
        # é‚®ç®±åŸŸååŒ¹é…
        if email1 and email2 and max_score < 0.7:
            domain1 = email1.split('@')[-1] if '@' in email1 else ''
            domain2 = email2.split('@')[-1] if '@' in email2 else ''
            
            if domain1 and domain2 and domain1.lower() == domain2.lower():
                email_match = {
                    'score': 0.7,
                    'type': 'email_domain_match',
                    'explanation': f'é‚®ç®±åŸŸååŒ¹é…: @{domain1}'
                }
                if 0.7 > max_score:
                    best_match = email_match
                    max_score = 0.7
        
        return best_match
    
    def _analyze_position_relationship(self, pos1: str, pos2: str) -> Dict:
        """èŒä½å…³ç³»åˆ†æ"""
        if not pos1 or not pos2 or pos1 == 'æœªçŸ¥' or pos2 == 'æœªçŸ¥':
            return {'score': 0, 'type': 'no_data', 'explanation': 'ç¼ºå°‘èŒä½ä¿¡æ¯'}
        
        # æ£€æŸ¥èŒä½å±‚çº§å…³ç³»
        hierarchy_score = self._check_position_hierarchy(pos1, pos2)
        if hierarchy_score > 0:
            return {
                'score': 0.6,
                'type': 'hierarchy_relation',
                'explanation': f'å¯èƒ½å­˜åœ¨ä¸Šä¸‹çº§å…³ç³»: {pos1} â†” {pos2}',
                'hierarchy_confidence': hierarchy_score
            }
        
        # æ£€æŸ¥èŒä½äº’è¡¥æ€§
        complementary_score = self._calculate_position_complementarity_advanced(pos1, pos2)
        if complementary_score > 0.5:
            return {
                'score': 0.7,
                'type': 'complementary_positions',
                'explanation': f'èŒä½äº’è¡¥å…³ç³»: {pos1} âŸ· {pos2}',
                'complementary_score': complementary_score
            }
        
        # ç›¸ä¼¼èŒä½
        similarity = self._calculate_advanced_similarity(pos1, pos2)
        if similarity > 0.6:
            return {
                'score': 0.5,
                'type': 'similar_positions',
                'explanation': f'ç›¸ä¼¼èŒä½: {pos1} ~ {pos2}',
                'similarity': similarity
            }
        
        return {'score': 0, 'type': 'no_match', 'explanation': 'èŒä½å…³ç³»ä¸æ˜ç¡®'}
    
    def _calculate_type_compatibility(
        self, 
        profile1: Dict, 
        profile2: Dict, 
        relationship_type: str
    ) -> Dict:
        """è®¡ç®—å…³ç³»ç±»å‹é€‚é…æ€§"""
        baseline_config = self.relationship_baselines.get(
            relationship_type, 
            {'base': 0.3, 'company_boost': 0.2, 'location_boost': 0.1}
        )
        
        base_score = baseline_config['base']
        total_boost = 0
        
        # æ ¹æ®å…³ç³»ç±»å‹è®¡ç®—é€‚é…æ€§æå‡
        if relationship_type == 'colleague':
            company1 = profile1.get('company', '').strip()
            company2 = profile2.get('company', '').strip()
            if company1 and company2 and company1.lower() == company2.lower():
                total_boost += baseline_config.get('company_boost', 0.3)
        
        elif relationship_type == 'alumni':
            edu1 = profile1.get('education', '').strip()
            edu2 = profile2.get('education', '').strip()
            if edu1 and edu2:
                similarity = self._calculate_advanced_similarity(edu1, edu2)
                if similarity > 0.7:
                    total_boost += baseline_config.get('education_boost', 0.3)
        
        elif relationship_type in ['neighbor', 'same_location']:
            loc1 = profile1.get('location', '').strip()
            loc2 = profile2.get('location', '').strip()
            if loc1 and loc2:
                similarity = self._calculate_advanced_similarity(loc1, loc2)
                if similarity > 0.6:
                    total_boost += baseline_config.get('location_boost', 0.4)
        
        final_score = min(base_score + total_boost, 1.0)
        
        return {
            'type_score': final_score,
            'base_score': base_score,
            'boost_applied': total_boost,
            'explanation': f'{relationship_type}ç±»å‹é€‚é…æ€§: {final_score:.2f}'
        }
    
    def _evaluate_evidence_strength(self, evidence: Dict) -> Dict:
        """è¯„ä¼°è¯æ®å¼ºåº¦"""
        if not evidence:
            return {'score': 0.3, 'explanation': 'ç¼ºå°‘æ”¯æŒè¯æ®'}
        
        evidence_factors = []
        total_score = 0.3  # åŸºç¡€åˆ†æ•°
        
        # æ£€æŸ¥åŒ¹é…å­—æ®µæ•°é‡
        matched_fields = evidence.get('matched_fields', [])
        if isinstance(matched_fields, list) and len(matched_fields) > 0:
            field_score = min(len(matched_fields) * 0.15, 0.3)
            total_score += field_score
            evidence_factors.append(f"{len(matched_fields)}ä¸ªå­—æ®µåŒ¹é…")
        
        # æ£€æŸ¥AIåˆ†æè´¨é‡
        if evidence.get('ai_analysis_quality'):
            total_score += 0.2
            evidence_factors.append("AIåˆ†ææ”¯æŒ")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        completeness = evidence.get('data_completeness', 0)
        if completeness > 0.7:
            total_score += 0.15
            evidence_factors.append("æ•°æ®å®Œæ•´")
        elif completeness > 0.5:
            total_score += 0.1
            evidence_factors.append("æ•°æ®è¾ƒå®Œæ•´")
        
        # æ£€æŸ¥äº¤å‰éªŒè¯
        if evidence.get('cross_validated'):
            total_score += 0.15
            evidence_factors.append("äº¤å‰éªŒè¯")
        
        return {
            'score': min(total_score, 1.0),
            'factors': evidence_factors,
            'explanation': f"è¯æ®å¼ºåº¦: {', '.join(evidence_factors) if evidence_factors else 'åŸºç¡€è¯æ®'}"
        }
    
    def _compute_final_confidence(
        self,
        field_scores: Dict,
        type_score: Dict,
        evidence_score: Dict,
        method_factor: float,
        relationship_type: str
    ) -> Tuple[float, Dict]:
        """è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦"""
        
        # åŠ æƒå­—æ®µåˆ†æ•°
        weighted_field_score = 0
        field_contributions = {}
        
        for field_name, field_data in field_scores.items():
            weight = self.field_weights.get(field_name, 0.1)
            contribution = field_data['score'] * weight
            weighted_field_score += contribution
            field_contributions[field_name] = {
                'score': field_data['score'],
                'weight': weight,
                'contribution': contribution
            }
        
        # ç»¼åˆè®¡ç®—
        base_confidence = (
            weighted_field_score * 0.5 +           # å­—æ®µåŒ¹é… 50%
            type_score['type_score'] * 0.3 +       # ç±»å‹é€‚é… 30% 
            evidence_score['score'] * 0.2          # è¯æ®å¼ºåº¦ 20%
        )
        
        # åº”ç”¨æ–¹æ³•å¯é æ€§è°ƒæ•´
        final_confidence = base_confidence * method_factor
        
        # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
        final_confidence = max(0.05, min(final_confidence, 0.98))
        
        breakdown = {
            'field_contribution': weighted_field_score,
            'type_contribution': type_score['type_score'],
            'evidence_contribution': evidence_score['score'],
            'method_reliability': method_factor,
            'base_confidence': base_confidence,
            'field_details': field_contributions
        }
        
        return final_confidence, breakdown
    
    def _calculate_advanced_similarity(self, str1: str, str2: str) -> float:
        """é«˜çº§å­—ç¬¦ä¸²ç›¸ä¼¼åº¦è®¡ç®—"""
        if not str1 or not str2:
            return 0.0
        
        # ä½¿ç”¨SequenceMatcherè·å¾—æ›´å‡†ç¡®çš„ç›¸ä¼¼åº¦
        similarity = SequenceMatcher(None, str1.lower().strip(), str2.lower().strip()).ratio()
        
        # Jaccardç›¸ä¼¼åº¦ä½œä¸ºè¡¥å……
        set1 = set(str1.lower())
        set2 = set(str2.lower())
        jaccard = len(set1 & set2) / len(set1 | set2) if len(set1 | set2) > 0 else 0
        
        # ç»¼åˆç›¸ä¼¼åº¦ï¼ˆåºåˆ—ç›¸ä¼¼åº¦æƒé‡æ›´é«˜ï¼‰
        return similarity * 0.7 + jaccard * 0.3
    
    def _extract_school_name(self, education: str) -> Optional[str]:
        """ä»æ•™è‚²ä¿¡æ¯ä¸­æå–å­¦æ ¡åç§°"""
        if not education:
            return None
        
        # å¸¸è§å­¦æ ¡å…³é”®è¯
        school_patterns = [
            r'([^ï¼Œ,ï¼›;ã€‚.]*?å¤§å­¦)',
            r'([^ï¼Œ,ï¼›;ã€‚.]*?å­¦é™¢)',
            r'([^ï¼Œ,ï¼›;ã€‚.]*?å­¦æ ¡)',
            r'([^ï¼Œ,ï¼›;ã€‚.]*?å¤§ä¸“)',
            r'([^ï¼Œ,ï¼›;ã€‚.]*?èŒä¸šæŠ€æœ¯å­¦é™¢)'
        ]
        
        for pattern in school_patterns:
            match = re.search(pattern, education)
            if match:
                return match.group(1).strip()
        
        return education.strip()
    
    def _parse_location(self, location: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
        """è§£æåœ°ç†ä½ç½®ä¿¡æ¯"""
        if not location:
            return None, None, None
        
        # ç®€åŒ–çš„åœ°ç†ä½ç½®è§£æ
        parts = location.replace('ï¼Œ', ',').replace('ã€', ',').split(',')
        
        city = None
        province = None
        country = None
        
        if len(parts) >= 3:
            city = parts[-3].strip()
            province = parts[-2].strip()
            country = parts[-1].strip()
        elif len(parts) == 2:
            city = parts[0].strip()
            province = parts[1].strip()
            country = 'ä¸­å›½'  # é»˜è®¤
        elif len(parts) == 1:
            city = parts[0].strip()
        
        return city, province, country
    
    def _compare_phone_numbers(self, phone1: str, phone2: str) -> float:
        """æ¯”è¾ƒç”µè¯å·ç ç›¸ä¼¼åº¦"""
        if not phone1 or not phone2:
            return 0.0
        
        # æ¸…ç†ç”µè¯å·ç æ ¼å¼
        clean1 = re.sub(r'[^\d]', '', phone1)
        clean2 = re.sub(r'[^\d]', '', phone2)
        
        if clean1 == clean2:
            return 1.0
        
        # æ£€æŸ¥å7ä½æ˜¯å¦ç›¸åŒï¼ˆå¿½ç•¥åŒºå·ï¼‰
        if len(clean1) >= 7 and len(clean2) >= 7:
            if clean1[-7:] == clean2[-7:]:
                return 0.8
        
        return 0.0
    
    def _check_company_relationship(self, company1: str, company2: str) -> float:
        """æ£€æŸ¥å…¬å¸å…³è”å…³ç³»"""
        # ç®€åŒ–çš„å…¬å¸å…³ç³»æ£€æµ‹
        keywords1 = set(company1.lower().split())
        keywords2 = set(company2.lower().split())
        
        # æ£€æŸ¥å…±åŒå…³é”®è¯
        common_words = keywords1 & keywords2
        if len(common_words) > 0:
            return min(len(common_words) / max(len(keywords1), len(keywords2)), 0.8)
        
        return 0.0
    
    def _check_position_hierarchy(self, pos1: str, pos2: str) -> float:
        """æ£€æŸ¥èŒä½å±‚çº§å…³ç³»"""
        senior_keywords = ['æ€»', 'å‰¯æ€»', 'ä¸»ä»»', 'ç»ç†', 'æ€»ç›‘', 'ä¸»ç®¡', 'VP', 'CEO', 'CTO', 'CFO']
        junior_keywords = ['åŠ©ç†', 'ä¸“å‘˜', 'å®ä¹ ', 'åˆçº§', 'è§ä¹ ']
        
        pos1_lower = pos1.lower()
        pos2_lower = pos2.lower()
        
        pos1_senior = any(keyword in pos1_lower for keyword in senior_keywords)
        pos2_senior = any(keyword in pos2_lower for keyword in senior_keywords)
        pos1_junior = any(keyword in pos1_lower for keyword in junior_keywords)
        pos2_junior = any(keyword in pos2_lower for keyword in junior_keywords)
        
        if (pos1_senior and pos2_junior) or (pos2_senior and pos1_junior):
            return 0.8
        elif pos1_senior and pos2_senior:
            return 0.6  # å¯èƒ½æ˜¯åŒçº§
        
        return 0.0
    
    def _calculate_position_complementarity_advanced(self, pos1: str, pos2: str) -> float:
        """é«˜çº§èŒä½äº’è¡¥æ€§è®¡ç®—"""
        complementary_matrix = {
            'é”€å”®': ['é‡‡è´­', 'å®¢æˆ·ç»ç†', 'å•†åŠ¡'],
            'äº§å“': ['å¼€å‘', 'è®¾è®¡', 'æŠ€æœ¯'],
            'å¸‚åœº': ['å“ç‰Œ', 'è¿è¥', 'æ¨å¹¿'],
            'è´¢åŠ¡': ['å®¡è®¡', 'æŠ•èµ„', 'é£æ§'],
            'äººäº‹': ['æ‹›è˜', 'åŸ¹è®­', 'è¡Œæ”¿'],
            'æŠ•èµ„': ['åˆ›ä¸š', 'ä¼ä¸šå‘å±•', 'é¡¹ç›®']
        }
        
        pos1_lower = pos1.lower()
        pos2_lower = pos2.lower()
        
        for key, complements in complementary_matrix.items():
            if key in pos1_lower:
                for complement in complements:
                    if complement in pos2_lower:
                        return 0.8
            elif key in pos2_lower:
                for complement in complements:
                    if complement in pos1_lower:
                        return 0.8
        
        return 0.0
    
    def _generate_quality_indicators(self, confidence: float, breakdown: Dict) -> Dict:
        """ç”Ÿæˆè´¨é‡æŒ‡æ ‡"""
        quality_level = 'low'
        if confidence >= 0.8:
            quality_level = 'high'
        elif confidence >= 0.6:
            quality_level = 'medium'
        
        indicators = {
            'overall_quality': quality_level,
            'confidence_tier': f'T{int((confidence * 10) // 2) + 1}',  # T1-T5åˆ†çº§
            'reliability_score': confidence,
            'data_sufficiency': len(breakdown.get('field_details', {})) >= 2,
            'multi_factor_support': breakdown.get('field_contribution', 0) > 0.3 and breakdown.get('evidence_contribution', 0) > 0.4
        }
        
        return indicators
    
    def _suggest_improvements(self, field_scores: Dict, evidence_score: Dict) -> List[str]:
        """æå‡ºæ”¹è¿›å»ºè®®"""
        suggestions = []
        
        if len(field_scores) < 2:
            suggestions.append("å¢åŠ æ›´å¤šå­—æ®µåŒ¹é…ä»¥æé«˜ç½®ä¿¡åº¦")
        
        if evidence_score['score'] < 0.5:
            suggestions.append("æ”¶é›†æ›´å¤šæ”¯æŒè¯æ®")
        
        if 'company' not in field_scores and 'colleague' in str(field_scores):
            suggestions.append("éªŒè¯å…¬å¸ä¿¡æ¯ä»¥ç¡®è®¤åŒäº‹å…³ç³»")
        
        if 'location' not in field_scores:
            suggestions.append("è¡¥å……åœ°ç†ä½ç½®ä¿¡æ¯")
        
        return suggestions