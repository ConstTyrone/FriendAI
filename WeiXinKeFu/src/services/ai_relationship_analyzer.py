"""
AIå¢å¼ºçš„å…³ç³»è¯†åˆ«åˆ†æå™¨
é›†æˆé€šä¹‰åƒé—®APIè¿›è¡Œæ™ºèƒ½å…³ç³»è¯†åˆ«å’Œåˆ†æ
"""

import os
import json
import logging
from typing import Dict, List, Tuple, Optional
import requests
import time
from datetime import datetime

# å¯¼å…¥æ–°çš„ç½®ä¿¡åº¦è®¡ç®—å¼•æ“
from .confidence_calculator import AdvancedConfidenceCalculator

logger = logging.getLogger(__name__)

class AIRelationshipAnalyzer:
    """AIå¢å¼ºçš„å…³ç³»è¯†åˆ«åˆ†æå™¨"""
    
    def __init__(self):
        self.api_key = os.getenv('QWEN_API_KEY')
        self.api_endpoint = os.getenv('QWEN_API_ENDPOINT', 'https://dashscope.aliyuncs.com/compatible-mode/v1')
        
        # åˆå§‹åŒ–ç½®ä¿¡åº¦è®¡ç®—å¼•æ“
        self.confidence_calculator = AdvancedConfidenceCalculator()
        logger.info("âœ… é«˜çº§ç½®ä¿¡åº¦è®¡ç®—å¼•æ“å·²åˆå§‹åŒ–")
        
        if not self.api_key:
            logger.warning("æœªé…ç½®QWEN_API_KEYï¼ŒAIå¢å¼ºåŠŸèƒ½å°†æ— æ³•ä½¿ç”¨")
            
        # AIåˆ†æé…ç½®
        self.config = {
            'model': 'qwen-plus',
            'temperature': 0.3,  # è¾ƒä½çš„æ¸©åº¦ç¡®ä¿ä¸€è‡´æ€§
            'max_tokens': 2000,
            'timeout': 30
        }
        
        # å…³ç³»ç±»å‹æ˜ å°„å’Œæƒé‡
        self.relationship_types = {
            'colleague': {'weight': 0.8, 'confidence_boost': 0.1},
            'friend': {'weight': 0.7, 'confidence_boost': 0.05},
            'partner': {'weight': 0.9, 'confidence_boost': 0.15},
            'client': {'weight': 0.85, 'confidence_boost': 0.12},
            'supplier': {'weight': 0.8, 'confidence_boost': 0.1},
            'alumni': {'weight': 0.6, 'confidence_boost': 0.08},
            'family': {'weight': 0.95, 'confidence_boost': 0.2},
            'neighbor': {'weight': 0.4, 'confidence_boost': 0.05},
            'same_location': {'weight': 0.3, 'confidence_boost': 0.02},
            'competitor': {'weight': 0.7, 'confidence_boost': 0.08},
            'investor': {'weight': 0.9, 'confidence_boost': 0.15}
        }
        
    def analyze_relationship_with_ai(self, profile1: Dict, profile2: Dict) -> Dict:
        """
        ä½¿ç”¨AIåˆ†æä¸¤ä¸ªè”ç³»äººä¹‹é—´çš„æ½œåœ¨å…³ç³»
        
        Args:
            profile1: ç¬¬ä¸€ä¸ªè”ç³»äººçš„èµ„æ–™
            profile2: ç¬¬äºŒä¸ªè”ç³»äººçš„èµ„æ–™
            
        Returns:
            åˆ†æç»“æœå­—å…¸ï¼ŒåŒ…å«å…³ç³»ç±»å‹ã€ç½®ä¿¡åº¦ã€è¯æ®ç­‰
        """
        try:
            # æ„å»ºAIæç¤ºè¯
            prompt = self._build_relationship_analysis_prompt(profile1, profile2)
            
            # è°ƒç”¨AI API
            ai_response = self._call_qwen_api(prompt)
            
            if not ai_response:
                return self._create_fallback_analysis(profile1, profile2)
            
            # è§£æAIå“åº”
            analysis_result = self._parse_ai_response(ai_response, profile1, profile2)
            
            # ä½¿ç”¨é«˜çº§ç½®ä¿¡åº¦è®¡ç®—å¼•æ“é‡æ–°è®¡ç®—ç½®ä¿¡åº¦
            enhanced_result = self._enhance_analysis_with_advanced_confidence(
                analysis_result, profile1, profile2
            )
            
            return enhanced_result
            
        except Exception as e:
            logger.error(f"AIå…³ç³»åˆ†æå¤±è´¥: {e}")
            return self._create_fallback_analysis(profile1, profile2)
    
    def _build_relationship_analysis_prompt(self, profile1: Dict, profile2: Dict) -> str:
        """æ„å»ºå…³ç³»åˆ†ææç¤ºè¯"""
        
        # æå–å…³é”®ä¿¡æ¯
        p1_info = self._extract_profile_info(profile1)
        p2_info = self._extract_profile_info(profile2)
        
        prompt = f"""
ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„ç¤¾äº¤å…³ç³»åˆ†æä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹ä¸¤ä¸ªè”ç³»äººä¹‹é—´å¯èƒ½å­˜åœ¨çš„å…³ç³»ï¼š

è”ç³»äººAï¼š{p1_info['name']}
- å…¬å¸ï¼š{p1_info['company']}
- èŒä½ï¼š{p1_info['position']}
- åœ°åŒºï¼š{p1_info['location']}
- å­¦å†ï¼š{p1_info['education']}
- è¡Œä¸šï¼š{p1_info['industry']}
- æ ‡ç­¾ï¼š{', '.join(p1_info['tags'])}

è”ç³»äººBï¼š{p2_info['name']}
- å…¬å¸ï¼š{p2_info['company']}
- èŒä½ï¼š{p2_info['position']}
- åœ°åŒºï¼š{p2_info['location']}
- å­¦å†ï¼š{p2_info['education']}
- è¡Œä¸šï¼š{p2_info['industry']}
- æ ‡ç­¾ï¼š{', '.join(p2_info['tags'])}

è¯·åˆ†æä»–ä»¬ä¹‹é—´å¯èƒ½çš„å…³ç³»ç±»å‹ï¼Œå¹¶æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š

1. æœ€å¯èƒ½çš„å…³ç³»ç±»å‹ï¼ˆä»ä»¥ä¸‹é€‰æ‹©ï¼‰ï¼š
   - colleagueï¼ˆåŒäº‹ï¼‰
   - friendï¼ˆæœ‹å‹ï¼‰
   - partnerï¼ˆåˆä½œä¼™ä¼´ï¼‰
   - clientï¼ˆå®¢æˆ·å…³ç³»ï¼‰
   - supplierï¼ˆä¾›åº”å•†ï¼‰
   - alumniï¼ˆæ ¡å‹ï¼‰
   - familyï¼ˆå®¶äººï¼‰
   - neighborï¼ˆé‚»å±…ï¼‰
   - same_locationï¼ˆåŒåœ°åŒºï¼‰
   - competitorï¼ˆç«äº‰å¯¹æ‰‹ï¼‰
   - investorï¼ˆæŠ•èµ„å…³ç³»ï¼‰

2. ç½®ä¿¡åº¦ï¼ˆ0-1ä¹‹é—´çš„å°æ•°ï¼‰

3. å…³ç³»æ–¹å‘ï¼š
   - bidirectionalï¼ˆåŒå‘å…³ç³»ï¼‰
   - A_to_Bï¼ˆAåˆ°Bçš„å•å‘å…³ç³»ï¼‰
   - B_to_Aï¼ˆBåˆ°Açš„å•å‘å…³ç³»ï¼‰

4. å…³ç³»å¼ºåº¦ï¼ˆstrong/medium/weakï¼‰

5. æ”¯æŒè¯æ®ï¼ˆå…·ä½“è¯´æ˜ä¸ºä»€ä¹ˆè®¤ä¸ºä»–ä»¬æœ‰è¿™ç§å…³ç³»ï¼‰

6. åŒ¹é…çš„å­—æ®µï¼ˆå“ªäº›ä¿¡æ¯å­—æ®µæ”¯æŒè¿™ä¸ªå…³ç³»åˆ¤æ–­ï¼‰

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
    "relationship_type": "å…³ç³»ç±»å‹",
    "confidence_score": ç½®ä¿¡åº¦æ•°å€¼,
    "relationship_direction": "å…³ç³»æ–¹å‘",
    "relationship_strength": "å…³ç³»å¼ºåº¦",
    "evidence": "è¯¦ç»†çš„è¯æ®è¯´æ˜",
    "matched_fields": ["åŒ¹é…çš„å­—æ®µåˆ—è¡¨"],
    "explanation": "ç®€çŸ­çš„å…³ç³»è¯´æ˜",
    "ai_reasoning": "AIçš„æ¨ç†è¿‡ç¨‹"
}}

è¯·åŸºäºæä¾›çš„ä¿¡æ¯è¿›è¡Œå®¢è§‚ã€å‡†ç¡®çš„åˆ†æã€‚å¦‚æœä¿¡æ¯ä¸è¶³ä»¥ç¡®å®šæ˜ç¡®å…³ç³»ï¼Œè¯·è®¾ç½®è¾ƒä½çš„ç½®ä¿¡åº¦ã€‚
"""
        return prompt
    
    def _extract_profile_info(self, profile: Dict) -> Dict:
        """æå–è”ç³»äººå…³é”®ä¿¡æ¯"""
        return {
            'name': profile.get('profile_name', profile.get('name', 'æœªçŸ¥')),
            'company': profile.get('company', 'æœªçŸ¥'),
            'position': profile.get('position', 'æœªçŸ¥'),
            'location': profile.get('location', profile.get('address', 'æœªçŸ¥')),
            'education': profile.get('education', 'æœªçŸ¥'),
            'industry': self._extract_industry_from_company(profile.get('company', '')),
            'tags': profile.get('tags', []) if isinstance(profile.get('tags', []), list) else []
        }
    
    def _extract_industry_from_company(self, company: str) -> str:
        """ä»å…¬å¸åç§°æå–è¡Œä¸šä¿¡æ¯"""
        if not company or company == 'æœªçŸ¥':
            return 'æœªçŸ¥'
        
        # ç®€å•çš„è¡Œä¸šè¯†åˆ«é€»è¾‘
        industry_keywords = {
            'ç§‘æŠ€': ['ç§‘æŠ€', 'æŠ€æœ¯', 'è½¯ä»¶', 'ç½‘ç»œ', 'IT', 'äº’è”ç½‘', 'æ•°æ®', 'äººå·¥æ™ºèƒ½', 'AI'],
            'é‡‘è': ['é“¶è¡Œ', 'é‡‘è', 'æŠ•èµ„', 'ä¿é™©', 'è¯åˆ¸', 'åŸºé‡‘', 'æ”¯ä»˜'],
            'åˆ¶é€ ': ['åˆ¶é€ ', 'ç”Ÿäº§', 'å·¥å‚', 'æœºæ¢°', 'æ±½è½¦', 'ç”µå­'],
            'æ•™è‚²': ['æ•™è‚²', 'å­¦æ ¡', 'åŸ¹è®­', 'å­¦é™¢', 'å¤§å­¦'],
            'åŒ»ç–—': ['åŒ»é™¢', 'åŒ»ç–—', 'è¯', 'å¥åº·', 'ç”Ÿç‰©'],
            'æˆ¿åœ°äº§': ['æˆ¿åœ°äº§', 'åœ°äº§', 'å»ºç­‘', 'è£…ä¿®'],
            'é›¶å”®': ['é›¶å”®', 'å•†åœº', 'è¶…å¸‚', 'ç”µå•†', 'è´­ç‰©'],
            'åª’ä½“': ['åª’ä½“', 'å¹¿å‘Š', 'ä¼ åª’', 'æ–‡åŒ–', 'å¨±ä¹']
        }
        
        for industry, keywords in industry_keywords.items():
            for keyword in keywords:
                if keyword in company:
                    return industry
        
        return 'å…¶ä»–'
    
    def _call_qwen_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨é€šä¹‰åƒé—®API"""
        if not self.api_key:
            return None
            
        try:
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': self.config['model'],
                'messages': [
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'temperature': self.config['temperature'],
                'max_tokens': self.config['max_tokens']
            }
            
            response = requests.post(
                f"{self.api_endpoint}/chat/completions",
                headers=headers,
                json=data,
                timeout=self.config['timeout']
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and result['choices']:
                    return result['choices'][0]['message']['content']
            else:
                logger.error(f"AI APIè°ƒç”¨å¤±è´¥: {response.status_code}, {response.text}")
                
        except requests.exceptions.Timeout:
            logger.error("AI APIè°ƒç”¨è¶…æ—¶")
        except Exception as e:
            logger.error(f"AI APIè°ƒç”¨å¼‚å¸¸: {e}")
            
        return None
    
    def _parse_ai_response(self, ai_response: str, profile1: Dict, profile2: Dict) -> Dict:
        """è§£æAIå“åº”"""
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            if ai_response.startswith('{') and ai_response.endswith('}'):
                return json.loads(ai_response)
            
            # å°è¯•æå–JSONéƒ¨åˆ†
            start_idx = ai_response.find('{')
            end_idx = ai_response.rfind('}')
            
            if start_idx != -1 and end_idx != -1:
                json_str = ai_response[start_idx:end_idx+1]
                return json.loads(json_str)
            
            # JSONè§£æå¤±è´¥ï¼Œå°è¯•æå–å…³é”®ä¿¡æ¯
            return self._extract_info_from_text(ai_response)
            
        except json.JSONDecodeError as e:
            logger.error(f"AIå“åº”JSONè§£æå¤±è´¥: {e}")
            return self._extract_info_from_text(ai_response)
        except Exception as e:
            logger.error(f"AIå“åº”è§£æå¼‚å¸¸: {e}")
            return self._create_default_analysis()
    
    def _extract_info_from_text(self, text: str) -> Dict:
        """ä»æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯"""
        result = self._create_default_analysis()
        
        # å°è¯•æå–å…³ç³»ç±»å‹
        for rel_type in self.relationship_types.keys():
            if rel_type in text.lower() or self._get_chinese_name(rel_type) in text:
                result['relationship_type'] = rel_type
                break
        
        # å°è¯•æå–ç½®ä¿¡åº¦
        import re
        confidence_match = re.search(r'ç½®ä¿¡åº¦[:ï¼š]?\s*(\d*\.?\d+)', text)
        if confidence_match:
            try:
                confidence = float(confidence_match.group(1))
                if confidence > 1:
                    confidence = confidence / 100  # ç™¾åˆ†æ¯”è½¬å°æ•°
                result['confidence_score'] = min(max(confidence, 0), 1)
            except ValueError:
                pass
        
        # æå–è¯æ®è¯´æ˜
        if 'è¯æ®' in text or 'ç†ç”±' in text:
            evidence_start = max(text.find('è¯æ®'), text.find('ç†ç”±'))
            if evidence_start != -1:
                evidence_text = text[evidence_start:evidence_start+200]
                result['evidence'] = evidence_text
        
        return result
    
    def _get_chinese_name(self, rel_type: str) -> str:
        """è·å–å…³ç³»ç±»å‹çš„ä¸­æ–‡åç§°"""
        chinese_names = {
            'colleague': 'åŒäº‹',
            'friend': 'æœ‹å‹',
            'partner': 'åˆä½œä¼™ä¼´',
            'client': 'å®¢æˆ·',
            'supplier': 'ä¾›åº”å•†',
            'alumni': 'æ ¡å‹',
            'family': 'å®¶äºº',
            'neighbor': 'é‚»å±…',
            'same_location': 'åŒåœ°åŒº',
            'competitor': 'ç«äº‰å¯¹æ‰‹',
            'investor': 'æŠ•èµ„'
        }
        return chinese_names.get(rel_type, rel_type)
    
    def _create_default_analysis(self) -> Dict:
        """åˆ›å»ºé»˜è®¤åˆ†æç»“æœ"""
        return {
            'relationship_type': 'colleague',
            'confidence_score': 0.5,
            'relationship_direction': 'bidirectional',
            'relationship_strength': 'medium',
            'evidence': 'AIåˆ†æä¸­ï¼Œä¿¡æ¯ä¸è¶³',
            'matched_fields': [],
            'explanation': 'éœ€è¦æ›´å¤šä¿¡æ¯ç¡®å®šå…³ç³»',
            'ai_reasoning': 'AIåˆ†æè¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜ï¼Œä½¿ç”¨é»˜è®¤åˆ†æ'
        }
    
    def _enhance_analysis_with_rules(self, analysis: Dict, profile1: Dict, profile2: Dict) -> Dict:
        """ä½¿ç”¨è§„åˆ™å¢å¼ºAIåˆ†æç»“æœ"""
        try:
            enhanced = analysis.copy()
            
            # åŸºäºå­—æ®µåŒ¹é…å¢å¼ºç½®ä¿¡åº¦
            field_matches = self._calculate_field_matches(profile1, profile2)
            
            # æ›´æ–°åŒ¹é…å­—æ®µ
            if not enhanced.get('matched_fields'):
                enhanced['matched_fields'] = list(field_matches.keys())
            
            # åŸºäºåŒ¹é…å¼ºåº¦è°ƒæ•´ç½®ä¿¡åº¦
            match_score = sum(field_matches.values()) / max(len(field_matches), 1)
            
            # è·å–å…³ç³»ç±»å‹é…ç½®
            rel_type = enhanced.get('relationship_type', 'colleague')
            type_config = self.relationship_types.get(rel_type, {'weight': 0.5, 'confidence_boost': 0})
            
            # è®¡ç®—å¢å¼ºç½®ä¿¡åº¦
            base_confidence = enhanced.get('confidence_score', 0.5)
            field_boost = match_score * 0.3  # å­—æ®µåŒ¹é…å¢å¼º
            type_boost = type_config['confidence_boost']  # å…³ç³»ç±»å‹å¢å¼º
            
            enhanced_confidence = min(base_confidence + field_boost + type_boost, 1.0)
            enhanced['confidence_score'] = enhanced_confidence
            
            # æ ¹æ®ç½®ä¿¡åº¦è°ƒæ•´å…³ç³»å¼ºåº¦
            if enhanced_confidence > 0.8:
                enhanced['relationship_strength'] = 'strong'
            elif enhanced_confidence < 0.4:
                enhanced['relationship_strength'] = 'weak'
            else:
                enhanced['relationship_strength'] = 'medium'
            
            # å¢å¼ºè¯æ®è¯´æ˜
            evidence_parts = [enhanced.get('evidence', '')]
            
            if field_matches:
                match_descriptions = []
                for field, score in field_matches.items():
                    if score > 0.7:
                        match_descriptions.append(f"{field}é«˜åº¦åŒ¹é…")
                    elif score > 0.3:
                        match_descriptions.append(f"{field}éƒ¨åˆ†åŒ¹é…")
                
                if match_descriptions:
                    evidence_parts.append(f"å­—æ®µåŒ¹é…: {', '.join(match_descriptions)}")
            
            enhanced['evidence'] = '; '.join(filter(None, evidence_parts))
            
            # æ·»åŠ åˆ†æå…ƒæ•°æ®
            enhanced['analysis_metadata'] = {
                'ai_used': True,
                'field_match_score': match_score,
                'enhanced_confidence': enhanced_confidence,
                'original_confidence': base_confidence,
                'analysis_timestamp': datetime.now().isoformat()
            }
            
            return enhanced
            
        except Exception as e:
            logger.error(f"å¢å¼ºåˆ†æå¤±è´¥: {e}")
            return analysis
    
    def _enhance_analysis_with_advanced_confidence(self, analysis: Dict, profile1: Dict, profile2: Dict) -> Dict:
        """ä½¿ç”¨é«˜çº§ç½®ä¿¡åº¦è®¡ç®—å¼•æ“å¢å¼ºåˆ†æç»“æœ"""
        try:
            logger.info("ğŸ” ä½¿ç”¨é«˜çº§ç½®ä¿¡åº¦è®¡ç®—å¼•æ“é‡æ–°è¯„ä¼°å…³ç³»")
            
            relationship_type = analysis.get('relationship_type', 'colleague')
            evidence = analysis.get('evidence', {})
            if isinstance(evidence, str):
                try:
                    evidence = json.loads(evidence)
                except:
                    evidence = {'raw_evidence': evidence}
            
            # å‡†å¤‡è¯æ®æ•°æ®
            enhanced_evidence = {
                **evidence,
                'ai_analysis_quality': True,
                'matched_fields': analysis.get('matched_fields', []),
                'data_completeness': self._calculate_data_completeness(profile1, profile2),
                'cross_validated': True  # AIåˆ†ææœ¬èº«å°±æ˜¯äº¤å‰éªŒè¯
            }
            
            # ä½¿ç”¨é«˜çº§ç½®ä¿¡åº¦è®¡ç®—å¼•æ“
            confidence_score, detailed_analysis = self.confidence_calculator.calculate_comprehensive_confidence(
                profile1=profile1,
                profile2=profile2,
                relationship_type=relationship_type,
                evidence=enhanced_evidence,
                method='ai_inference'
            )
            
            # æ›´æ–°åˆ†æç»“æœ
            enhanced_result = analysis.copy()
            enhanced_result.update({
                'confidence_score': confidence_score,
                'detailed_confidence_analysis': detailed_analysis,
                'enhanced_by_advanced_calculator': True,
                
                # æ ¹æ®æ–°ç½®ä¿¡åº¦è°ƒæ•´å…³ç³»å¼ºåº¦
                'relationship_strength': self._determine_relationship_strength(confidence_score),
                
                # å¢å¼ºçš„è¯æ®æè¿°
                'evidence_detailed': self._build_evidence_description(detailed_analysis),
                
                # è´¨é‡æŒ‡æ ‡
                'quality_indicators': detailed_analysis.get('quality_indicators', {}),
                
                # æ”¹è¿›å»ºè®®
                'improvement_suggestions': detailed_analysis.get('improvement_suggestions', [])
            })
            
            logger.info(f"âœ… é«˜çº§ç½®ä¿¡åº¦è®¡ç®—å®Œæˆ - åŸå§‹: {analysis.get('confidence_score', 0):.3f} â†’ æ–°: {confidence_score:.3f}")
            return enhanced_result
            
        except Exception as e:
            logger.error(f"âŒ é«˜çº§ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
            # é™çº§åˆ°åŸæœ‰æ–¹æ³•
            return self._enhance_analysis_with_rules(analysis, profile1, profile2)
    
    def _calculate_data_completeness(self, profile1: Dict, profile2: Dict) -> float:
        """è®¡ç®—æ•°æ®å®Œæ•´æ€§åˆ†æ•°"""
        important_fields = ['company', 'position', 'location', 'education', 'phone', 'email']
        total_score = 0
        
        for profile in [profile1, profile2]:
            profile_score = 0
            for field in important_fields:
                value = profile.get(field, '').strip()
                if value and value != 'æœªçŸ¥':
                    profile_score += 1
            total_score += profile_score / len(important_fields)
        
        return total_score / 2  # å¹³å‡å®Œæ•´æ€§
    
    def _determine_relationship_strength(self, confidence_score: float) -> str:
        """æ ¹æ®ç½®ä¿¡åº¦ç¡®å®šå…³ç³»å¼ºåº¦"""
        if confidence_score >= 0.8:
            return 'strong'
        elif confidence_score >= 0.6:
            return 'medium'
        elif confidence_score >= 0.4:
            return 'weak'
        else:
            return 'very_weak'
    
    def _build_evidence_description(self, detailed_analysis: Dict) -> str:
        """æ„å»ºè¯¦ç»†çš„è¯æ®æè¿°"""
        description_parts = []
        
        # å­—æ®µåˆ†ææè¿°
        field_analysis = detailed_analysis.get('field_analysis', {})
        for field, data in field_analysis.items():
            if data.get('score', 0) > 0.5:
                description_parts.append(f"{field}: {data.get('explanation', 'åŒ¹é…')}")
        
        # ç±»å‹é€‚é…æ€§æè¿°
        type_analysis = detailed_analysis.get('type_compatibility', {})
        if type_analysis.get('type_score', 0) > 0.5:
            description_parts.append(f"ç±»å‹é€‚é…: {type_analysis.get('explanation', 'è‰¯å¥½')}")
        
        # è´¨é‡æŒ‡æ ‡
        quality = detailed_analysis.get('quality_indicators', {})
        quality_level = quality.get('overall_quality', 'unknown')
        if quality_level != 'unknown':
            description_parts.append(f"æ•´ä½“è´¨é‡: {quality_level}")
        
        return '; '.join(description_parts) if description_parts else 'åŸºäºAIåˆ†æ'
    
    def _calculate_field_matches(self, profile1: Dict, profile2: Dict) -> Dict[str, float]:
        """è®¡ç®—å­—æ®µåŒ¹é…åˆ†æ•°"""
        matches = {}
        
        # å…¬å¸åŒ¹é…
        company1 = profile1.get('company', '').strip()
        company2 = profile2.get('company', '').strip()
        if company1 and company2 and company1 != 'æœªçŸ¥' and company2 != 'æœªçŸ¥':
            if company1.lower() == company2.lower():
                matches['company'] = 1.0
            else:
                # ç®€å•çš„ç›¸ä¼¼åº¦è®¡ç®—
                similarity = self._calculate_similarity(company1, company2)
                if similarity > 0.7:
                    matches['company'] = similarity
        
        # åœ°åŒºåŒ¹é…
        location1 = profile1.get('location', profile1.get('address', '')).strip()
        location2 = profile2.get('location', profile2.get('address', '')).strip()
        if location1 and location2 and location1 != 'æœªçŸ¥' and location2 != 'æœªçŸ¥':
            similarity = self._calculate_similarity(location1, location2)
            if similarity > 0.5:
                matches['location'] = similarity
        
        # æ•™è‚²åŒ¹é…
        education1 = profile1.get('education', '').strip()
        education2 = profile2.get('education', '').strip()
        if education1 and education2 and education1 != 'æœªçŸ¥' and education2 != 'æœªçŸ¥':
            similarity = self._calculate_similarity(education1, education2)
            if similarity > 0.6:
                matches['education'] = similarity
        
        # èŒä½ç›¸å…³æ€§
        position1 = profile1.get('position', '').strip()
        position2 = profile2.get('position', '').strip()
        if position1 and position2 and position1 != 'æœªçŸ¥' and position2 != 'æœªçŸ¥':
            # æ£€æŸ¥èŒä½äº’è¡¥æ€§ï¼ˆå¦‚é”€å”®å’Œå®¢æˆ·ç»ç†ï¼‰
            complementary_score = self._calculate_position_complementarity(position1, position2)
            if complementary_score > 0.3:
                matches['position_complementary'] = complementary_score
        
        return matches
    
    def _calculate_similarity(self, str1: str, str2: str) -> float:
        """è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        if not str1 or not str2:
            return 0.0
        
        # ç®€å•çš„Jaccardç›¸ä¼¼åº¦
        set1 = set(str1.lower())
        set2 = set(str2.lower())
        
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        
        return intersection / union if union > 0 else 0.0
    
    def _calculate_position_complementarity(self, pos1: str, pos2: str) -> float:
        """è®¡ç®—èŒä½äº’è¡¥æ€§"""
        complementary_pairs = [
            (['é”€å”®', 'ä¸šåŠ¡'], ['å®¢æˆ·', 'é‡‡è´­']),
            (['äº§å“', 'è®¾è®¡'], ['å¼€å‘', 'å·¥ç¨‹']),
            (['å¸‚åœº', 'è¥é”€'], ['å“ç‰Œ', 'æ¨å¹¿']),
            (['è´¢åŠ¡', 'ä¼šè®¡'], ['å®¡è®¡', 'é£æ§']),
            (['HR', 'äººäº‹'], ['æ‹›è˜', 'åŸ¹è®­']),
            (['æŠ•èµ„', 'åŸºé‡‘'], ['åˆ›ä¸š', 'ä¼ä¸š'])
        ]
        
        pos1_lower = pos1.lower()
        pos2_lower = pos2.lower()
        
        for group1, group2 in complementary_pairs:
            if any(keyword in pos1_lower for keyword in group1) and \
               any(keyword in pos2_lower for keyword in group2):
                return 0.8
            if any(keyword in pos2_lower for keyword in group1) and \
               any(keyword in pos1_lower for keyword in group2):
                return 0.8
        
        return 0.0
    
    def _create_fallback_analysis(self, profile1: Dict, profile2: Dict) -> Dict:
        """åˆ›å»ºå¤‡ç”¨åˆ†æç»“æœï¼ˆä¸ä½¿ç”¨AIï¼‰"""
        # åŸºäºè§„åˆ™çš„ç®€å•åˆ†æ
        field_matches = self._calculate_field_matches(profile1, profile2)
        
        # ç¡®å®šå…³ç³»ç±»å‹
        relationship_type = 'colleague'  # é»˜è®¤
        confidence = 0.3  # è¾ƒä½çš„é»˜è®¤ç½®ä¿¡åº¦
        
        if 'company' in field_matches and field_matches['company'] > 0.8:
            relationship_type = 'colleague'
            confidence = 0.7
        elif 'education' in field_matches and field_matches['education'] > 0.7:
            relationship_type = 'alumni'
            confidence = 0.6
        elif 'location' in field_matches and field_matches['location'] > 0.7:
            relationship_type = 'same_location'
            confidence = 0.5
        elif 'position_complementary' in field_matches:
            relationship_type = 'partner'
            confidence = 0.65
        
        return {
            'relationship_type': relationship_type,
            'confidence_score': confidence,
            'relationship_direction': 'bidirectional',
            'relationship_strength': 'medium' if confidence > 0.6 else 'weak',
            'evidence': f'åŸºäºå­—æ®µåŒ¹é…åˆ†æ: {", ".join(field_matches.keys())}',
            'matched_fields': list(field_matches.keys()),
            'explanation': f'ç³»ç»Ÿæ£€æµ‹åˆ°{self._get_chinese_name(relationship_type)}å…³ç³»',
            'ai_reasoning': 'æœªä½¿ç”¨AIåˆ†æï¼ŒåŸºäºè§„åˆ™åŒ¹é…',
            'analysis_metadata': {
                'ai_used': False,
                'field_match_score': sum(field_matches.values()) / max(len(field_matches), 1),
                'analysis_timestamp': datetime.now().isoformat()
            }
        }
    
    def batch_analyze_relationships(self, profile_pairs: List[Tuple[Dict, Dict]]) -> List[Dict]:
        """
        æ‰¹é‡åˆ†æå…³ç³»
        
        Args:
            profile_pairs: è”ç³»äººå¯¹åˆ—è¡¨
            
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        
        for i, (profile1, profile2) in enumerate(profile_pairs):
            try:
                logger.info(f"æ‰¹é‡åˆ†æè¿›åº¦: {i+1}/{len(profile_pairs)}")
                
                result = self.analyze_relationship_with_ai(profile1, profile2)
                results.append(result)
                
                # é¿å…APIé¢‘ç‡é™åˆ¶
                if i < len(profile_pairs) - 1:
                    time.sleep(0.5)
                    
            except Exception as e:
                logger.error(f"æ‰¹é‡åˆ†æç¬¬{i+1}ä¸ªå…³ç³»å¯¹å¤±è´¥: {e}")
                results.append(self._create_fallback_analysis(profile1, profile2))
        
        return results
    
    def get_relationship_suggestions(self, target_profile: Dict, candidate_profiles: List[Dict], top_k: int = 10) -> List[Dict]:
        """
        ä¸ºç›®æ ‡è”ç³»äººè·å–å…³ç³»å»ºè®®
        
        Args:
            target_profile: ç›®æ ‡è”ç³»äºº
            candidate_profiles: å€™é€‰è”ç³»äººåˆ—è¡¨
            top_k: è¿”å›å‰Kä¸ªå»ºè®®
            
        Returns:
            å…³ç³»å»ºè®®åˆ—è¡¨ï¼ŒæŒ‰ç½®ä¿¡åº¦é™åºæ’åˆ—
        """
        suggestions = []
        
        for candidate in candidate_profiles:
            if candidate.get('id') == target_profile.get('id'):
                continue
                
            analysis = self.analyze_relationship_with_ai(target_profile, candidate)
            
            # åªä¿ç•™ç½®ä¿¡åº¦è¾ƒé«˜çš„å»ºè®®
            if analysis.get('confidence_score', 0) >= 0.4:
                suggestions.append({
                    'target_profile': target_profile,
                    'candidate_profile': candidate,
                    'analysis': analysis
                })
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        suggestions.sort(key=lambda x: x['analysis'].get('confidence_score', 0), reverse=True)
        
        return suggestions[:top_k]