"""
LLMæ„å›¾åŒ¹é…åˆ¤æ–­æœåŠ¡
ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ·±åº¦è¯­ä¹‰ç†è§£å’Œç²¾ç¡®åŒ¹é…åˆ¤æ–­
"""

import json
import asyncio
import hashlib
import logging
import requests
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)

class MatchStrategy(Enum):
    """åŒ¹é…ç­–ç•¥æšä¸¾"""
    VECTOR_ONLY = "vector_only"  # ä»…å‘é‡
    LLM_ONLY = "llm_only"  # ä»…LLM
    HYBRID = "hybrid"  # æ··åˆ
    ADAPTIVE = "adaptive"  # è‡ªé€‚åº”

class ComplexityLevel(Enum):
    """æ„å›¾å¤æ‚åº¦çº§åˆ«"""
    SIMPLE = "simple"  # ç®€å•
    MODERATE = "moderate"  # ä¸­ç­‰
    COMPLEX = "complex"  # å¤æ‚

@dataclass
class MatchJudgment:
    """LLMåŒ¹é…åˆ¤æ–­ç»“æœ"""
    match_score: float  # åŒ¹é…åˆ†æ•° 0-1
    confidence: float  # ç½®ä¿¡åº¦ 0-1
    is_match: bool  # æ˜¯å¦åŒ¹é…
    matched_aspects: List[str]  # åŒ¹é…çš„æ–¹é¢
    missing_aspects: List[str]  # ç¼ºå¤±çš„æ–¹é¢
    explanation: str  # è¯¦ç»†è§£é‡Š
    suggestions: Optional[str] = None  # æ”¹è¿›å»ºè®®
    strategy_used: str = "llm"  # ä½¿ç”¨çš„ç­–ç•¥
    processing_time: float = 0.0  # å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰
    cached: bool = False  # æ˜¯å¦æ¥è‡ªç¼“å­˜

class LLMMatchingService:
    """LLMæ„å›¾åŒ¹é…æœåŠ¡"""
    
    def __init__(self, qwen_api_key: str, db_path: str = "user_profiles.db", api_endpoint: str = None):
        """
        åˆå§‹åŒ–LLMåŒ¹é…æœåŠ¡
        
        Args:
            qwen_api_key: é€šä¹‰åƒé—®APIå¯†é’¥
            db_path: æ•°æ®åº“è·¯å¾„
            api_endpoint: APIç«¯ç‚¹ï¼ˆå¯é€‰ï¼‰
        """
        self.api_key = qwen_api_key
        self.db_path = db_path
        self.api_endpoint = api_endpoint or "https://dashscope.aliyuncs.com/compatible-mode/v1"
        self.cache = {}  # å†…å­˜ç¼“å­˜
        self.cache_ttl = timedelta(hours=24)  # ç¼“å­˜æœ‰æ•ˆæœŸ
        
        # é…ç½®å‚æ•°
        self.batch_size = 5  # æ‰¹å¤„ç†å¤§å°
        self.max_parallel = 3  # æœ€å¤§å¹¶è¡Œæ•°
        self.timeout = 30  # APIè°ƒç”¨è¶…æ—¶ï¼ˆç§’ï¼‰
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        logger.info(f"âœ… LLMåŒ¹é…æœåŠ¡åˆå§‹åŒ–æˆåŠŸ (ä½¿ç”¨HTTPè¯·æ±‚æ–¹å¼)")
        logger.info(f"   APIç«¯ç‚¹: {self.api_endpoint}")
    
    async def judge_match(
        self,
        intent: Dict,
        profile: Dict,
        context: Optional[Dict] = None,
        use_cache: bool = True
    ) -> MatchJudgment:
        """
        ä½¿ç”¨LLMåˆ¤æ–­æ„å›¾ä¸è”ç³»äººæ˜¯å¦åŒ¹é…
        
        Args:
            intent: æ„å›¾ä¿¡æ¯
            profile: è”ç³»äººä¿¡æ¯
            context: é¢å¤–ä¸Šä¸‹æ–‡
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns:
            MatchJudgment: åŒ¹é…åˆ¤æ–­ç»“æœ
        """
        start_time = datetime.now()
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache:
            cache_key = self._generate_cache_key(intent, profile)
            cached_result = self._get_from_cache(cache_key)
            if cached_result:
                cached_result.cached = True
                logger.info(f"ğŸ¯ å‘½ä¸­ç¼“å­˜: {cache_key[:16]}...")
                return cached_result
        
        try:
            # æ„å»ºprompt
            prompt = self._build_judgment_prompt(intent, profile, context)
            
            # è°ƒç”¨LLM
            response = await self._call_llm(prompt)
            
            # è§£æå“åº”
            judgment = self._parse_judgment(response)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            judgment.processing_time = (datetime.now() - start_time).total_seconds()
            
            # å­˜å…¥ç¼“å­˜
            if use_cache:
                self._save_to_cache(cache_key, judgment)
            
            logger.info(f"âœ… LLMåˆ¤æ–­å®Œæˆ: åˆ†æ•°={judgment.match_score:.2f}, è€—æ—¶={judgment.processing_time:.2f}s")
            return judgment
            
        except Exception as e:
            logger.error(f"âŒ LLMåˆ¤æ–­å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ç»“æœ
            return MatchJudgment(
                match_score=0.0,
                confidence=0.0,
                is_match=False,
                matched_aspects=[],
                missing_aspects=[],
                explanation=f"LLMåˆ¤æ–­å¤±è´¥: {str(e)}",
                processing_time=(datetime.now() - start_time).total_seconds()
            )
    
    async def batch_judge(
        self,
        intent: Dict,
        profiles: List[Dict],
        strategy: MatchStrategy = MatchStrategy.ADAPTIVE,
        parallel: bool = True
    ) -> List[MatchJudgment]:
        """
        æ‰¹é‡åˆ¤æ–­å¤šä¸ªè”ç³»äºº
        
        Args:
            intent: æ„å›¾ä¿¡æ¯
            profiles: è”ç³»äººåˆ—è¡¨
            strategy: åŒ¹é…ç­–ç•¥
            parallel: æ˜¯å¦å¹¶è¡Œå¤„ç†
            
        Returns:
            åˆ¤æ–­ç»“æœåˆ—è¡¨
        """
        if not profiles:
            return []
        
        # æ ¹æ®ç­–ç•¥è¿‡æ»¤å€™é€‰
        candidates = await self._filter_candidates(intent, profiles, strategy)
        
        if parallel and len(candidates) > 1:
            # å¹¶è¡Œå¤„ç†
            return await self._parallel_judge(intent, candidates)
        else:
            # ä¸²è¡Œå¤„ç†
            results = []
            for profile in candidates:
                judgment = await self.judge_match(intent, profile)
                results.append(judgment)
            return results
    
    async def explain_mismatch(
        self,
        intent: Dict,
        profile: Dict
    ) -> str:
        """
        è§£é‡Šä¸ºä»€ä¹ˆä¸åŒ¹é…
        
        Args:
            intent: æ„å›¾ä¿¡æ¯
            profile: è”ç³»äººä¿¡æ¯
            
        Returns:
            ä¸åŒ¹é…çš„è¯¦ç»†è§£é‡Š
        """
        prompt = self._build_mismatch_prompt(intent, profile)
        
        try:
            response = await self._call_llm(prompt)
            return response
        except Exception as e:
            logger.error(f"ç”Ÿæˆä¸åŒ¹é…è§£é‡Šå¤±è´¥: {e}")
            return "æ— æ³•ç”Ÿæˆè¯¦ç»†è§£é‡Š"
    
    def assess_complexity(self, intent: Dict) -> ComplexityLevel:
        """
        è¯„ä¼°æ„å›¾å¤æ‚åº¦
        
        Args:
            intent: æ„å›¾ä¿¡æ¯
            
        Returns:
            å¤æ‚åº¦çº§åˆ«
        """
        score = 0
        
        # æ£€æŸ¥æ¡ä»¶æ•°é‡
        conditions = intent.get('conditions', {})
        required = conditions.get('required', [])
        preferred = conditions.get('preferred', [])
        
        score += len(required) * 2
        score += len(preferred)
        
        # æ£€æŸ¥æè¿°é•¿åº¦å’Œå¤æ‚åº¦
        description = intent.get('description', '')
        if len(description) > 200:
            score += 3
        if any(word in description for word in ['ä¸è¦', 'é™¤äº†', 'ä½†æ˜¯', 'æˆ–è€…']):
            score += 2
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤æ‚é€»è¾‘
        if 'ä¸”' in description or 'æˆ–' in description:
            score += 2
        
        # åˆ¤æ–­å¤æ‚åº¦çº§åˆ«
        if score <= 3:
            return ComplexityLevel.SIMPLE
        elif score <= 8:
            return ComplexityLevel.MODERATE
        else:
            return ComplexityLevel.COMPLEX
    
    def _build_judgment_prompt(
        self,
        intent: Dict,
        profile: Dict,
        context: Optional[Dict] = None
    ) -> str:
        """æ„å»ºåˆ¤æ–­prompt"""
        
        # æå–æ„å›¾ä¿¡æ¯
        intent_info = f"""
æ„å›¾åç§°ï¼š{intent.get('name', 'æœªå‘½å')}
æ„å›¾ç±»å‹ï¼š{intent.get('type', 'æœªåˆ†ç±»')}
æ„å›¾æè¿°ï¼š{intent.get('description', 'æ— æè¿°')}
ä¼˜å…ˆçº§ï¼š{intent.get('priority', 5)}/10
"""
        
        # æå–æ¡ä»¶ä¿¡æ¯
        conditions = intent.get('conditions', {})
        if conditions:
            required = conditions.get('required', [])
            preferred = conditions.get('preferred', [])
            keywords = conditions.get('keywords', [])
            
            conditions_info = ""
            if required:
                conditions_info += f"å¿…éœ€æ¡ä»¶ï¼š{json.dumps(required, ensure_ascii=False, indent=2)}\n"
            if preferred:
                conditions_info += f"åå¥½æ¡ä»¶ï¼š{json.dumps(preferred, ensure_ascii=False, indent=2)}\n"
            if keywords:
                conditions_info += f"å…³é”®è¯ï¼š{', '.join(keywords)}\n"
        else:
            conditions_info = "æ— ç‰¹å®šæ¡ä»¶"
        
        # æå–è”ç³»äººä¿¡æ¯
        profile_info = f"""
å§“åï¼š{profile.get('profile_name', profile.get('name', 'æœªçŸ¥'))}
å¾®ä¿¡IDï¼š{profile.get('wechat_id', 'æœªçŸ¥')}
ç”µè¯ï¼š{profile.get('phone', 'æœªçŸ¥')}
"""
        
        # åŸºæœ¬ä¿¡æ¯
        basic_info = profile.get('basic_info', {})
        if basic_info:
            profile_info += f"åŸºæœ¬ä¿¡æ¯ï¼š{json.dumps(basic_info, ensure_ascii=False, indent=2)}\n"
        
        # æ ‡ç­¾
        tags = profile.get('tags', [])
        if tags:
            profile_info += f"æ ‡ç­¾ï¼š{', '.join(tags)}\n"
        
        # æœ€è¿‘æ´»åŠ¨
        activities = profile.get('recent_activities', [])
        if activities:
            profile_info += f"æœ€è¿‘æ´»åŠ¨ï¼š{json.dumps(activities[:3], ensure_ascii=False, indent=2)}\n"
        
        # æ„å»ºå®Œæ•´prompt
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„å•†åŠ¡åŒ¹é…ä¸“å®¶ï¼Œæ“…é•¿å‘ç°äººæ‰æ½œåŠ›å’Œåˆä½œæœºä¼šã€‚ä½ çš„ç›®æ ‡æ˜¯å¸®åŠ©ç”¨æˆ·å‘ç°æœ‰ä»·å€¼çš„è”ç³»äººã€‚

## æ ¸å¿ƒä»»åŠ¡
åˆ†ææ„å›¾å’Œè”ç³»äººçš„åŒ¹é…åº¦ï¼Œé‡‡ç”¨**ç§¯æä¹è§‚**çš„è¯„åˆ¤æ ‡å‡†ï¼Œé‡ç‚¹æŒ–æ˜åŒ¹é…çš„å¯èƒ½æ€§ã€‚

## æ„å›¾ä¿¡æ¯
{intent_info}

### åŒ¹é…æ¡ä»¶
{conditions_info}

## è”ç³»äººä¿¡æ¯
{profile_info}

## ğŸ¯ æ™ºèƒ½è¯„åˆ†åŸåˆ™

### 1. åŸºç¡€åˆ†æ•°èµ·ç‚¹é«˜
- åªè¦æœ‰**ä»»ä½•ç›¸å…³æ€§**ï¼ŒåŸºç¡€åˆ†å°±ä» 0.5 èµ·æ­¥
- æœ‰**è¡Œä¸šç›¸å…³æ€§**ï¼ŒåŸºç¡€åˆ†ä» 0.6 èµ·æ­¥
- æœ‰**ç›´æ¥å…³é”®è¯åŒ¹é…**ï¼ŒåŸºç¡€åˆ†ä» 0.7 èµ·æ­¥

### 2. åŠ åˆ†é¡¹ï¼ˆæ¯é¡¹+0.1åˆ°+0.2ï¼‰
- è¡Œä¸šèƒŒæ™¯ç›¸å…³æˆ–ç›¸è¿‘
- èŒä½/è§’è‰²æœ‰å…³è”æ€§
- åœ°åŸŸæ¥è¿‘æˆ–å¯è¿œç¨‹åˆä½œ
- å¹´é¾„åœ¨åˆç†èŒƒå›´å†…ï¼ˆÂ±5å²ä¹Ÿå¯æ¥å—ï¼‰
- æœ‰ç›¸å…³æŠ€èƒ½æˆ–ç»éªŒ
- æ•™è‚²èƒŒæ™¯ç¬¦åˆæˆ–æ¥è¿‘
- äººè„‰èµ„æºå¯èƒ½æœ‰ä»·å€¼
- æ€§æ ¼ç‰¹å¾é€‚åˆåˆä½œ
- æœ‰æ½œåœ¨çš„ä¸šåŠ¡ååŒæ€§

### 3. æ™ºèƒ½ç†è§£æ„å›¾
- **ä¸è¦è¿‡åº¦è§£è¯»**å¿…éœ€æ¡ä»¶ï¼Œå¤§éƒ¨åˆ†æ¡ä»¶éƒ½æ˜¯"æœ€å¥½æœ‰"è€Œé"å¿…é¡»æœ‰"
- **çµæ´»ç†è§£**å…³é”®è¯ï¼Œä¾‹å¦‚"æŠ€æœ¯"å¯ä»¥åŒ…æ‹¬å„ç§æŠ€æœ¯ç›¸å…³è§’è‰²
- **è€ƒè™‘é—´æ¥ä»·å€¼**ï¼Œå¦‚è™½éç›®æ ‡äººé€‰ä½†å¯èƒ½ä»‹ç»åˆé€‚äººé€‰
- **è·¨ç•Œæ½œåŠ›**ï¼Œä¸åŒè¡Œä¸šç»éªŒå¯èƒ½å¸¦æ¥åˆ›æ–°è§†è§’

### 4. è¯„åˆ†æ ‡å‡†ï¼ˆæ›´å®½æ¾ï¼‰
- **0.85-1.0**: å®Œç¾åŒ¹é…ï¼Œç«‹å³æ¨èè”ç³»
- **0.75-0.85**: é«˜åº¦åŒ¹é…ï¼Œå¼ºçƒˆå»ºè®®äº†è§£
- **0.65-0.75**: è‰¯å¥½åŒ¹é…ï¼Œå€¼å¾—æ·±å…¥äº¤æµ
- **0.55-0.65**: æ½œåœ¨åŒ¹é…ï¼Œå¯ä»¥è¯•æ¢æ€§æ¥è§¦
- **0.45-0.55**: é—´æ¥ä»·å€¼ï¼Œå¯èƒ½é€šè¿‡å…¶è®¤è¯†ç›®æ ‡äººé€‰
- **0.35-0.45**: å¤‡é€‰è€ƒè™‘ï¼Œç‰¹å®šæ¡ä»¶ä¸‹å¯èƒ½æœ‰ç”¨
- **0.0-0.35**: æš‚æ— æ˜æ˜¾å…³è”ï¼ˆä»…åœ¨å®Œå…¨æ— å…³æ—¶ä½¿ç”¨ï¼‰

### 5. åˆ¤æ–­å¿ƒæ€
- é‡‡ç”¨**"å®å¯é”™æ€ï¼Œä¸å¯æ”¾è¿‡"**çš„ç­–ç•¥
- ç›¸ä¿¡**"æ¯ä¸ªäººéƒ½æœ‰å…¶ç‹¬ç‰¹ä»·å€¼"**
- è€ƒè™‘**"å…­åº¦åˆ†éš”ç†è®º"**ï¼Œé—´æ¥è”ç³»ä¹Ÿå¾ˆé‡è¦
- è®°ä½**"äººçš„æ½œåŠ›æ˜¯æ— é™çš„"**

## è¾“å‡ºæ ¼å¼
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
    "match_score": 0.78,
    "confidence": 0.85,
    "is_match": true,
    "matched_aspects": ["è¡Œä¸šèƒŒæ™¯ç›¸å…³", "æœ‰æŠ€æœ¯ç®¡ç†ç»éªŒ", "å¹´é¾„åˆé€‚", "åœ°åŸŸå¯æ¥å—"],
    "missing_aspects": ["éç›´æ¥æŠ€æœ¯å²—ä½"],
    "explanation": "è™½ç„¶è¯¥è”ç³»äººç›®å‰æ˜¯æŠ€æœ¯é¡¾é—®è€Œéçº¯æŠ€æœ¯å¼€å‘ï¼Œä½†å…¶æŠ€æœ¯èƒŒæ™¯å’Œç®¡ç†ç»éªŒéå¸¸æœ‰ä»·å€¼ã€‚æŠ€æœ¯é¡¾é—®é€šå¸¸å¯¹æŠ€æœ¯è¶‹åŠ¿å’Œäººæ‰å¸‚åœºæœ‰æ·±å…¥äº†è§£ï¼Œå¯èƒ½è®¤è¯†åˆé€‚çš„æŠ€æœ¯äººæ‰ã€‚å¹´é¾„å’Œåœ°åŸŸéƒ½åœ¨å¯æ¥å—èŒƒå›´å†…ã€‚",
    "suggestions": "å»ºè®®å…ˆäº†è§£å…¶æŠ€æœ¯ä¸“é•¿é¢†åŸŸå’Œäººè„‰èµ„æºï¼Œå³ä½¿æœ¬äººä¸å®Œå…¨åŒ¹é…ï¼Œä¹Ÿå¯èƒ½æ¨èåˆé€‚äººé€‰æˆ–æä¾›æœ‰ä»·å€¼çš„è¡Œä¸šè§è§£ã€‚"
}}

## âš ï¸ é‡è¦æé†’
- **é»˜è®¤ç»™é«˜åˆ†**ï¼šé™¤éæ˜æ˜¾å®Œå…¨ä¸ç›¸å…³ï¼Œå¦åˆ™åˆ†æ•°åº”è¯¥åœ¨0.5ä»¥ä¸Š
- **is_match é—¨æ§›ä½**ï¼šmatch_score >= 0.45 æ—¶å°±åº”è¯¥ is_match = true
- **è§£é‡Šè¦ç§¯æ**ï¼šå¤šè¯´ä¼˜ç‚¹å’Œå¯èƒ½æ€§ï¼Œå°‘è¯´ç¼ºç‚¹å’Œé—®é¢˜
- **å»ºè®®è¦åŠ¡å®**ï¼šæä¾›å…·ä½“çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®
- **ä¿æŒä¹è§‚**ï¼šç”¨ç§¯æçš„è¯­è¨€æè¿°åŒ¹é…æƒ…å†µ"""
        
        # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
        if context:
            prompt += f"\n\n## é¢å¤–ä¸Šä¸‹æ–‡\n{json.dumps(context, ensure_ascii=False, indent=2)}"
        
        return prompt
    
    def _build_mismatch_prompt(self, intent: Dict, profile: Dict) -> str:
        """æ„å»ºä¸åŒ¹é…è§£é‡Šçš„prompt"""
        return f"""åˆ†æä»¥ä¸‹æ„å›¾å’Œè”ç³»äººä¸ºä»€ä¹ˆä¸åŒ¹é…ï¼Œå¹¶æä¾›æ”¹è¿›å»ºè®®ã€‚

æ„å›¾ï¼š{json.dumps(intent, ensure_ascii=False, indent=2)}

è”ç³»äººï¼š{json.dumps(profile, ensure_ascii=False, indent=2)}

è¯·æä¾›ï¼š
1. ä¸»è¦ä¸åŒ¹é…åŸå› ï¼ˆæœ€é‡è¦çš„3ä¸ªï¼‰
2. å¦‚æœè¦åŒ¹é…ï¼Œè”ç³»äººéœ€è¦å…·å¤‡ä»€ä¹ˆ
3. å¦‚æœè¦åŒ¹é…ï¼Œæ„å›¾å¯ä»¥å¦‚ä½•è°ƒæ•´
4. å…¶ä»–å¯èƒ½æ›´åˆé€‚çš„åŒ¹é…æ–¹å‘

è¦æ±‚å›ç­”ç®€æ´ã€å®ç”¨ã€æœ‰å»ºè®¾æ€§ã€‚"""
    
    async def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLM API (ä½¿ç”¨å¼‚æ­¥æ–¹å¼çš„åŒæ­¥è¯·æ±‚)"""
        
        # æ„é€ è¯·æ±‚æ•°æ®
        data = {
            "model": "qwen-plus",  # æˆ– "qwen-max"
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ¹é…åˆ†æä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0,  # ä¿è¯ä¸€è‡´æ€§
            "max_tokens": 1000
        }
        
        try:
            # ä½¿ç”¨ asyncio è¿è¡ŒåŒæ­¥è¯·æ±‚
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: requests.post(
                    f"{self.api_endpoint}/chat/completions",
                    headers=self.headers,
                    data=json.dumps(data),
                    timeout=self.timeout
                )
            )
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                logger.info(f"LLMå“åº”æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(content)}")
                return content
            else:
                error_msg = f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}"
                logger.error(error_msg)
                raise Exception(error_msg)
                
        except requests.Timeout:
            raise Exception(f"LLMè°ƒç”¨è¶…æ—¶ï¼ˆ{self.timeout}ç§’ï¼‰")
        except Exception as e:
            logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def _parse_judgment(self, response: str) -> MatchJudgment:
        """è§£æLLMå“åº”"""
        try:
            # å°è¯•æå–JSON
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
            else:
                raise ValueError("å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°JSON")
            
            return MatchJudgment(
                match_score=float(data.get('match_score', 0)),
                confidence=float(data.get('confidence', 0)),
                is_match=bool(data.get('is_match', False)) or float(data.get('match_score', 0)) >= 0.45,  # æ›´å®½æ¾çš„é˜ˆå€¼
                matched_aspects=data.get('matched_aspects', []),
                missing_aspects=data.get('missing_aspects', []),
                explanation=data.get('explanation', ''),
                suggestions=data.get('suggestions'),
                strategy_used='llm'
            )
            
        except Exception as e:
            logger.error(f"è§£æLLMå“åº”å¤±è´¥: {e}\nåŸå§‹å“åº”: {response}")
            # è¿”å›é»˜è®¤ç»“æœ
            return MatchJudgment(
                match_score=0.0,
                confidence=0.0,
                is_match=False,
                matched_aspects=[],
                missing_aspects=[],
                explanation=f"è§£æå¤±è´¥: {response[:200]}...",
                strategy_used='llm'
            )
    
    def _generate_cache_key(self, intent: Dict, profile: Dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # ä½¿ç”¨å…³é”®å­—æ®µç”Ÿæˆå“ˆå¸Œ
        key_data = {
            'intent_id': intent.get('id'),
            'intent_desc': intent.get('description', ''),
            'intent_conditions': intent.get('conditions', {}),
            'profile_id': profile.get('id'),
            'profile_name': profile.get('profile_name', ''),
            'profile_tags': profile.get('tags', []),
            'profile_basic': profile.get('basic_info', {})
        }
        
        key_str = json.dumps(key_data, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def _get_from_cache(self, cache_key: str) -> Optional[MatchJudgment]:
        """ä»ç¼“å­˜è·å–ç»“æœ"""
        if cache_key in self.cache:
            cached_item = self.cache[cache_key]
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if datetime.now() - cached_item['time'] < self.cache_ttl:
                return cached_item['judgment']
            else:
                # è¿‡æœŸåˆ™åˆ é™¤
                del self.cache[cache_key]
        return None
    
    def _save_to_cache(self, cache_key: str, judgment: MatchJudgment):
        """ä¿å­˜åˆ°ç¼“å­˜"""
        self.cache[cache_key] = {
            'judgment': judgment,
            'time': datetime.now()
        }
        
        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self.cache) > 1000:
            # åˆ é™¤æœ€æ—§çš„é¡¹
            oldest_key = min(self.cache.keys(), 
                           key=lambda k: self.cache[k]['time'])
            del self.cache[oldest_key]
    
    async def _filter_candidates(
        self,
        intent: Dict,
        profiles: List[Dict],
        strategy: MatchStrategy
    ) -> List[Dict]:
        """æ ¹æ®ç­–ç•¥è¿‡æ»¤å€™é€‰è”ç³»äºº"""
        
        if strategy == MatchStrategy.LLM_ONLY:
            # LLMå¤„ç†æ‰€æœ‰
            return profiles
            
        elif strategy == MatchStrategy.VECTOR_ONLY:
            # ä¸ä½¿ç”¨LLM
            return []
            
        elif strategy == MatchStrategy.HYBRID:
            # ä½¿ç”¨å‘é‡è¿‡æ»¤Top K
            try:
                from .vector_service import vector_service
                # è·å–å‘é‡ç›¸ä¼¼åº¦æ’åº
                scored_profiles = []
                for profile in profiles:
                    score, _ = await vector_service.calculate_semantic_similarity(
                        intent, profile, use_cache=True
                    )
                    scored_profiles.append((score, profile))
                
                # æ’åºå¹¶å–Top K
                scored_profiles.sort(key=lambda x: x[0], reverse=True)
                top_k = min(20, len(scored_profiles))
                return [p for _, p in scored_profiles[:top_k]]
                
            except Exception as e:
                logger.error(f"å‘é‡è¿‡æ»¤å¤±è´¥: {e}")
                return profiles[:20]  # é™çº§å¤„ç†
                
        else:  # ADAPTIVE
            # æ ¹æ®å¤æ‚åº¦è‡ªé€‚åº”
            complexity = self.assess_complexity(intent)
            
            if complexity == ComplexityLevel.SIMPLE:
                # ç®€å•æ„å›¾ä¸ä½¿ç”¨LLM
                return []
            elif complexity == ComplexityLevel.MODERATE:
                # ä¸­ç­‰å¤æ‚åº¦ï¼Œé€‰æ‹©å‰10ä¸ª
                return profiles[:10]
            else:
                # å¤æ‚æ„å›¾ï¼Œé€‰æ‹©å‰20ä¸ª
                return profiles[:20]
    
    async def _parallel_judge(
        self,
        intent: Dict,
        profiles: List[Dict]
    ) -> List[MatchJudgment]:
        """å¹¶è¡Œåˆ¤æ–­å¤šä¸ªè”ç³»äºº"""
        
        # åˆ›å»ºä»»åŠ¡
        tasks = []
        for profile in profiles:
            task = self.judge_match(intent, profile)
            tasks.append(task)
        
        # åˆ†æ‰¹æ‰§è¡Œ
        results = []
        for i in range(0, len(tasks), self.max_parallel):
            batch = tasks[i:i + self.max_parallel]
            batch_results = await asyncio.gather(*batch, return_exceptions=True)
            
            for result in batch_results:
                if isinstance(result, Exception):
                    logger.error(f"å¹¶è¡Œåˆ¤æ–­å¤±è´¥: {result}")
                    # æ·»åŠ å¤±è´¥ç»“æœ
                    results.append(MatchJudgment(
                        match_score=0.0,
                        confidence=0.0,
                        is_match=False,
                        matched_aspects=[],
                        missing_aspects=[],
                        explanation=f"åˆ¤æ–­å¤±è´¥: {str(result)}"
                    ))
                else:
                    results.append(result)
        
        return results

# å…¨å±€å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
llm_matching_service = None

def init_llm_matching_service(api_key: str, db_path: str = "user_profiles.db", api_endpoint: str = None):
    """åˆå§‹åŒ–å…¨å±€LLMåŒ¹é…æœåŠ¡"""
    global llm_matching_service
    llm_matching_service = LLMMatchingService(api_key, db_path, api_endpoint)
    return llm_matching_service