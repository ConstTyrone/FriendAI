#!/usr/bin/env python3
"""
åé¦ˆæ•°æ®åˆ†æè„šæœ¬
ç”¨äºåˆ†æç”¨æˆ·åé¦ˆæ•°æ®ï¼Œè¯†åˆ«æ¨¡å¼å’Œæ”¹è¿›æœºä¼š
"""

import sqlite3
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import logging
import sys
import statistics

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class FeedbackAnalyzer:
    """åé¦ˆæ•°æ®åˆ†æå™¨"""
    
    def __init__(self, db_path: str = "user_profiles.db"):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path)
        self.cursor = self.conn.cursor()
        
    def get_feedback_data(self, user_id: str = None) -> List[Dict]:
        """è·å–åé¦ˆæ•°æ®"""
        query = """
            SELECT 
                im.*,
                ui.name as intent_name,
                ui.description as intent_description,
                ui.type as intent_type,
                ui.conditions as intent_conditions
            FROM intent_matches im
            LEFT JOIN user_intents ui ON im.intent_id = ui.id
            WHERE im.user_feedback IS NOT NULL
        """
        
        params = []
        if user_id:
            query += " AND im.user_id = ?"
            params.append(user_id)
            
        query += " ORDER BY im.created_at DESC"
        
        self.cursor.execute(query, params)
        columns = [desc[0] for desc in self.cursor.description]
        rows = self.cursor.fetchall()
        
        data = []
        for row in rows:
            record = dict(zip(columns, row))
            # è§£æJSONå­—æ®µ
            if record.get('matched_conditions'):
                try:
                    record['matched_conditions'] = json.loads(record['matched_conditions'])
                except:
                    record['matched_conditions'] = []
            if record.get('score_details'):
                try:
                    record['score_details'] = json.loads(record['score_details'])
                except:
                    record['score_details'] = {}
            data.append(record)
            
        return data
    
    def analyze_score_distribution(self, data: List[Dict]) -> Dict:
        """åˆ†æåˆ†æ•°åˆ†å¸ƒ"""
        if df.empty:
            return {
                'total': 0,
                'message': 'æ— åé¦ˆæ•°æ®'
            }
            
        results = {
            'total': len(df),
            'by_feedback': {},
            'score_stats': {},
            'score_separation': 0
        }
        
        # æŒ‰åé¦ˆç±»å‹åˆ†ç»„
        for feedback_type in ['positive', 'negative', 'ignored']:
            type_df = df[df['user_feedback'] == feedback_type]
            if not type_df.empty:
                results['by_feedback'][feedback_type] = {
                    'count': len(type_df),
                    'percentage': len(type_df) / len(df) * 100,
                    'avg_score': type_df['match_score'].mean(),
                    'std_score': type_df['match_score'].std(),
                    'min_score': type_df['match_score'].min(),
                    'max_score': type_df['match_score'].max(),
                    'median_score': type_df['match_score'].median()
                }
        
        # è®¡ç®—æ•´ä½“ç»Ÿè®¡
        results['score_stats'] = {
            'mean': df['match_score'].mean(),
            'std': df['match_score'].std(),
            'min': df['match_score'].min(),
            'max': df['match_score'].max(),
            'median': df['match_score'].median(),
            'q25': df['match_score'].quantile(0.25),
            'q75': df['match_score'].quantile(0.75)
        }
        
        # è®¡ç®—åˆ†æ•°åˆ†ç¦»åº¦
        if 'positive' in results['by_feedback'] and 'negative' in results['by_feedback']:
            results['score_separation'] = (
                results['by_feedback']['positive']['avg_score'] - 
                results['by_feedback']['negative']['avg_score']
            )
        
        return results
    
    def analyze_scoring_components(self, df: pd.DataFrame) -> Dict:
        """åˆ†æè¯„åˆ†ç»„ä»¶çš„è¡¨ç°"""
        if df.empty or 'score_details' not in df.columns:
            return {}
            
        components = {
            'vector_similarity': [],
            'keyword_score': [],
            'required_score': [],
            'preferred_score': []
        }
        
        feedback_components = {
            'positive': {k: [] for k in components.keys()},
            'negative': {k: [] for k in components.keys()},
            'ignored': {k: [] for k in components.keys()}
        }
        
        for _, row in df.iterrows():
            details = row.get('score_details', {})
            feedback = row.get('user_feedback')
            
            if details and feedback:
                for comp_name in components.keys():
                    if comp_name in details:
                        score = details[comp_name]
                        components[comp_name].append(score)
                        feedback_components[feedback][comp_name].append(score)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        results = {}
        
        # æ•´ä½“ç»„ä»¶ç»Ÿè®¡
        results['overall'] = {}
        for comp_name, scores in components.items():
            if scores:
                results['overall'][comp_name] = {
                    'mean': statistics.mean(scores),
                    'std': statistics.stdev(scores) if len(scores) > 1 else 0,
                    'contribution': statistics.mean(scores) if scores else 0
                }
        
        # æŒ‰åé¦ˆç±»å‹çš„ç»„ä»¶ç»Ÿè®¡
        results['by_feedback'] = {}
        for feedback_type, comp_dict in feedback_components.items():
            results['by_feedback'][feedback_type] = {}
            for comp_name, scores in comp_dict.items():
                if scores:
                    results['by_feedback'][feedback_type][comp_name] = {
                        'mean': statistics.mean(scores),
                        'std': statistics.stdev(scores) if len(scores) > 1 else 0,
                        'count': len(scores)
                    }
        
        # è®¡ç®—ç»„ä»¶åŒºåˆ†åº¦
        results['discriminative_power'] = {}
        for comp_name in components.keys():
            pos_scores = feedback_components['positive'][comp_name]
            neg_scores = feedback_components['negative'][comp_name]
            
            if pos_scores and neg_scores:
                # è®¡ç®—æ­£è´Ÿåé¦ˆçš„åˆ†æ•°å·®å¼‚
                results['discriminative_power'][comp_name] = {
                    'separation': statistics.mean(pos_scores) - statistics.mean(neg_scores),
                    'positive_mean': statistics.mean(pos_scores),
                    'negative_mean': statistics.mean(neg_scores),
                    'effectiveness': abs(statistics.mean(pos_scores) - statistics.mean(neg_scores))
                }
        
        return results
    
    def identify_patterns(self, data: List[Dict]) -> Dict:
        """è¯†åˆ«åé¦ˆæ¨¡å¼"""
        patterns = {
            'false_positives': [],  # é«˜åˆ†ä½†è´Ÿåé¦ˆ
            'false_negatives': [],  # ä½åˆ†ä½†æ­£åé¦ˆ
            'threshold_issues': [],  # é˜ˆå€¼é™„è¿‘çš„é—®é¢˜
            'component_issues': []   # ç»„ä»¶æƒé‡é—®é¢˜
        }
        
        if not data:
            return patterns
        
        # è¯†åˆ«å‡é˜³æ€§ï¼ˆé«˜åˆ†ä½†è´Ÿåé¦ˆï¼‰
        false_pos = [d for d in data if d.get('user_feedback') == 'negative' and d.get('match_score', 0) > 0.6]
        if false_pos:
            scores = [d.get('match_score', 0) for d in false_pos]
            patterns['false_positives'] = {
                'count': len(false_pos),
                'avg_score': statistics.mean(scores) if scores else 0,
                'examples': [{'intent_id': d.get('intent_id'), 'profile_id': d.get('profile_id'), 'match_score': d.get('match_score')} for d in false_pos[:5]]
            }
        
        # è¯†åˆ«å‡é˜´æ€§ï¼ˆä½åˆ†ä½†æ­£åé¦ˆï¼‰
        false_neg = [d for d in data if d.get('user_feedback') == 'positive' and d.get('match_score', 0) < 0.4]
        if false_neg:
            scores = [d.get('match_score', 0) for d in false_neg]
            patterns['false_negatives'] = {
                'count': len(false_neg),
                'avg_score': statistics.mean(scores) if scores else 0,
                'examples': [{'intent_id': d.get('intent_id'), 'profile_id': d.get('profile_id'), 'match_score': d.get('match_score')} for d in false_neg[:5]]
            }
        
        # è¯†åˆ«é˜ˆå€¼é—®é¢˜
        threshold_range = [d for d in data if 0.45 <= d.get('match_score', 0) <= 0.55]
        if threshold_range:
            positive_count = sum(1 for d in threshold_range if d.get('user_feedback') == 'positive')
            negative_count = sum(1 for d in threshold_range if d.get('user_feedback') == 'negative')
            positive_scores = sorted([d.get('match_score', 0) for d in data if d.get('user_feedback') == 'positive'])
            suggested_threshold = positive_scores[int(len(positive_scores) * 0.1)] if positive_scores else 0.5
            
            patterns['threshold_issues'] = {
                'count': len(threshold_range),
                'positive_rate': positive_count / len(threshold_range) if threshold_range else 0,
                'negative_rate': negative_count / len(threshold_range) if threshold_range else 0,
                'suggestion': 'è€ƒè™‘è°ƒæ•´é˜ˆå€¼åˆ°' + str(round(suggested_threshold, 2))
            }
        
        return patterns
    
    def generate_recommendations(self, analysis: Dict) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # åŸºäºåˆ†æ•°åˆ†ç¦»åº¦çš„å»ºè®®
        if 'score_distribution' in analysis:
            dist = analysis['score_distribution']
            if dist.get('score_separation', 0) < 0.2:
                recommendations.append(
                    "âš ï¸ åˆ†æ•°åˆ†ç¦»åº¦è¾ƒä½ï¼ˆ{:.2f}ï¼‰ï¼Œå»ºè®®å¢åŠ ç®—æ³•çš„åŒºåˆ†èƒ½åŠ›".format(
                        dist.get('score_separation', 0)
                    )
                )
            
            # æ£€æŸ¥åé¦ˆåˆ†å¸ƒ
            by_feedback = dist.get('by_feedback', {})
            if 'negative' in by_feedback:
                neg_rate = by_feedback['negative']['percentage']
                if neg_rate > 40:
                    recommendations.append(
                        f"ğŸ“‰ è´Ÿåé¦ˆç‡è¾ƒé«˜ï¼ˆ{neg_rate:.1f}%ï¼‰ï¼Œå»ºè®®æé«˜åŒ¹é…è´¨é‡"
                    )
        
        # åŸºäºç»„ä»¶åˆ†æçš„å»ºè®®
        if 'component_analysis' in analysis:
            comp = analysis['component_analysis']
            disc_power = comp.get('discriminative_power', {})
            
            for comp_name, stats in disc_power.items():
                if stats['effectiveness'] < 0.1:
                    recommendations.append(
                        f"ğŸ”§ ç»„ä»¶ {comp_name} åŒºåˆ†åº¦è¾ƒä½ï¼ˆ{stats['effectiveness']:.3f}ï¼‰ï¼Œè€ƒè™‘è°ƒæ•´æƒé‡"
                    )
        
        # åŸºäºæ¨¡å¼è¯†åˆ«çš„å»ºè®®
        if 'patterns' in analysis:
            patterns = analysis['patterns']
            
            if patterns.get('false_positives', {}).get('count', 0) > 5:
                recommendations.append(
                    "âŒ æ£€æµ‹åˆ°è¾ƒå¤šå‡é˜³æ€§ï¼ˆ{}ä¸ªï¼‰ï¼Œå»ºè®®æé«˜åŒ¹é…æ ‡å‡†".format(
                        patterns['false_positives']['count']
                    )
                )
            
            if patterns.get('false_negatives', {}).get('count', 0) > 5:
                recommendations.append(
                    "â­• æ£€æµ‹åˆ°è¾ƒå¤šå‡é˜´æ€§ï¼ˆ{}ä¸ªï¼‰ï¼Œå»ºè®®æ”¾å®½åŒ¹é…æ¡ä»¶".format(
                        patterns['false_negatives']['count']
                    )
                )
            
            if patterns.get('threshold_issues', {}).get('suggestion'):
                recommendations.append(
                    "ğŸ¯ " + patterns['threshold_issues']['suggestion']
                )
        
        # åŸºäºæ•°æ®é‡çš„å»ºè®®
        total_feedback = analysis.get('score_distribution', {}).get('total', 0)
        if total_feedback < 50:
            recommendations.append(
                f"ğŸ“Š å½“å‰åé¦ˆæ•°æ®è¾ƒå°‘ï¼ˆ{total_feedback}æ¡ï¼‰ï¼Œå»ºè®®ç»§ç»­æ”¶é›†è‡³å°‘{50-total_feedback}æ¡å†è¿›è¡Œä¼˜åŒ–"
            )
        
        return recommendations
    
    def export_analysis(self, analysis: Dict, output_path: str = None):
        """å¯¼å‡ºåˆ†æç»“æœ"""
        if output_path is None:
            output_path = f"feedback_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"åˆ†æç»“æœå·²å¯¼å‡ºåˆ°: {output_path}")
    
    def print_analysis_report(self, analysis: Dict):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“Š åé¦ˆæ•°æ®åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        # åŸºæœ¬ç»Ÿè®¡
        dist = analysis.get('score_distribution', {})
        print(f"\nğŸ“ˆ åŸºæœ¬ç»Ÿè®¡:")
        print(f"  æ€»åé¦ˆæ•°: {dist.get('total', 0)}")
        
        if dist.get('by_feedback'):
            print(f"\n  åé¦ˆåˆ†å¸ƒ:")
            for feedback_type, stats in dist.get('by_feedback', {}).items():
                print(f"    {feedback_type}: {stats['count']} ({stats['percentage']:.1f}%)")
                print(f"      å¹³å‡åˆ†: {stats['avg_score']:.3f} (Â±{stats['std_score']:.3f})")
        
        # åˆ†æ•°åˆ†ç¦»åº¦
        if dist.get('score_separation'):
            print(f"\n  åˆ†æ•°åˆ†ç¦»åº¦: {dist['score_separation']:.3f}")
            if dist['score_separation'] > 0.3:
                print("    âœ… è‰¯å¥½çš„åŒºåˆ†èƒ½åŠ›")
            elif dist['score_separation'] > 0.15:
                print("    âš ï¸ åŒºåˆ†èƒ½åŠ›ä¸€èˆ¬")
            else:
                print("    âŒ åŒºåˆ†èƒ½åŠ›è¾ƒå·®")
        
        # ç»„ä»¶åˆ†æ
        comp = analysis.get('component_analysis', {})
        if comp.get('discriminative_power'):
            print(f"\nğŸ”§ ç»„ä»¶åŒºåˆ†åº¦:")
            for comp_name, stats in comp['discriminative_power'].items():
                print(f"  {comp_name}:")
                print(f"    æ­£åé¦ˆå‡å€¼: {stats['positive_mean']:.3f}")
                print(f"    è´Ÿåé¦ˆå‡å€¼: {stats['negative_mean']:.3f}")
                print(f"    åŒºåˆ†åº¦: {stats['effectiveness']:.3f}")
        
        # é—®é¢˜æ¨¡å¼
        patterns = analysis.get('patterns', {})
        if patterns:
            print(f"\nâš ï¸ è¯†åˆ«çš„é—®é¢˜:")
            if patterns.get('false_positives', {}).get('count'):
                print(f"  å‡é˜³æ€§: {patterns['false_positives']['count']}ä¸ª")
            if patterns.get('false_negatives', {}).get('count'):
                print(f"  å‡é˜´æ€§: {patterns['false_negatives']['count']}ä¸ª")
            if patterns.get('threshold_issues', {}).get('suggestion'):
                print(f"  é˜ˆå€¼å»ºè®®: {patterns['threshold_issues']['suggestion']}")
        
        # ä¼˜åŒ–å»ºè®®
        recommendations = analysis.get('recommendations', [])
        if recommendations:
            print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            for i, rec in enumerate(recommendations, 1):
                print(f"  {i}. {rec}")
        
        print("\n" + "="*60 + "\n")
    
    def run_full_analysis(self, user_id: str = None) -> Dict:
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        logger.info("å¼€å§‹åé¦ˆæ•°æ®åˆ†æ...")
        
        # è·å–æ•°æ®
        data = self.get_feedback_data(user_id)
        
        if not data:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°åé¦ˆæ•°æ®")
            return {
                'status': 'no_data',
                'message': 'æš‚æ— åé¦ˆæ•°æ®ï¼Œè¯·ç»§ç»­æ”¶é›†'
            }
        
        logger.info(f"åŠ è½½äº† {len(data)} æ¡åé¦ˆæ•°æ®")
        
        # æ‰§è¡Œå„é¡¹åˆ†æ
        analysis = {
            'timestamp': datetime.now().isoformat(),
            'user_id': user_id,
            'score_distribution': self.analyze_score_distribution(data),
            'component_analysis': self.analyze_scoring_components(data),
            'patterns': self.identify_patterns(data),
        }
        
        # ç”Ÿæˆå»ºè®®
        analysis['recommendations'] = self.generate_recommendations(analysis)
        
        return analysis
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='åé¦ˆæ•°æ®åˆ†æå·¥å…·')
    parser.add_argument('--user-id', help='æŒ‡å®šç”¨æˆ·ID')
    parser.add_argument('--export', help='å¯¼å‡ºåˆ†æç»“æœåˆ°æ–‡ä»¶')
    parser.add_argument('--db', default='user_profiles.db', help='æ•°æ®åº“è·¯å¾„')
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = FeedbackAnalyzer(args.db)
    
    try:
        # è¿è¡Œåˆ†æ
        analysis = analyzer.run_full_analysis(args.user_id)
        
        # æ‰“å°æŠ¥å‘Š
        analyzer.print_analysis_report(analysis)
        
        # å¯¼å‡ºç»“æœï¼ˆå¦‚æœéœ€è¦ï¼‰
        if args.export:
            analyzer.export_analysis(analysis, args.export)
        
    except Exception as e:
        logger.error(f"åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        analyzer.close()


if __name__ == "__main__":
    main()