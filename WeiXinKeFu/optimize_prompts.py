#!/usr/bin/env python3
"""
æç¤ºè¯ä¼˜åŒ–å·¥å…· - æé«˜LLMåˆ¤æ–­è´¨é‡
é€šè¿‡ç³»ç»ŸåŒ–æµ‹è¯•å’Œä¼˜åŒ–æç¤ºè¯æ¥æå‡åŒ¹é…å‡†ç¡®æ€§
"""

import asyncio
import json
import time
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import logging
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.services.llm_matching_service import LLMMatchingService
from src.config.config import config

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class PromptVariant:
    """æç¤ºè¯å˜ä½“"""
    name: str
    system_prompt: str
    user_prompt_template: str
    features: List[str]  # ç‰¹æ€§ï¼šfew-shot, cot, structured, etc.
    
@dataclass
class PromptTestResult:
    """æç¤ºè¯æµ‹è¯•ç»“æœ"""
    variant_name: str
    accuracy: float
    avg_confidence: float
    avg_response_time: float
    correct_matches: int
    total_tests: int
    false_positives: int
    false_negatives: int

class PromptOptimizer:
    """æç¤ºè¯ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.llm_service = LLMMatchingService(
            api_key=config.qwen_api_key,
            api_endpoint=config.qwen_api_endpoint
        )
        self.test_cases = self.create_test_cases()
        self.prompt_variants = self.create_prompt_variants()
    
    def create_test_cases(self) -> List[Dict]:
        """åˆ›å»ºæµ‹è¯•ç”¨ä¾‹"""
        return [
            {
                "intent": {
                    "name": "å¯»æ‰¾Pythonå¼€å‘å·¥ç¨‹å¸ˆ",
                    "description": "éœ€è¦ä¸€ä½æœ‰3å¹´ä»¥ä¸Šç»éªŒçš„Pythonå¼€å‘å·¥ç¨‹å¸ˆï¼Œç†Ÿæ‚‰Djangoæˆ–Flaskæ¡†æ¶",
                    "conditions": {
                        "required": ["Python", "3å¹´ç»éªŒ"],
                        "preferred": ["Django", "Flask", "AIç»éªŒ"]
                    }
                },
                "profile": {
                    "name": "å¼ ä¸‰",
                    "position": "Pythoné«˜çº§å·¥ç¨‹å¸ˆ",
                    "skills": ["Python", "Django", "Flask", "AI"],
                    "experience": "5å¹´"
                },
                "expected_match": True,
                "expected_score_min": 0.8
            },
            {
                "intent": {
                    "name": "åˆ›ä¸šåˆä¼™äºº",
                    "description": "å¯»æ‰¾å¿—åŒé“åˆçš„åˆ›ä¸šä¼™ä¼´ï¼Œæœ€å¥½æœ‰åˆ›ä¸šç»éªŒï¼Œèƒ½æ‰¿å—å‹åŠ›",
                    "conditions": {
                        "required": ["åˆ›ä¸šæ„æ„¿", "æ‰¿å‹èƒ½åŠ›"],
                        "preferred": ["åˆ›ä¸šç»éªŒ", "æŠ€æœ¯èƒŒæ™¯"]
                    }
                },
                "profile": {
                    "name": "æå››",
                    "position": "CEO",
                    "background": "è¿ç»­åˆ›ä¸šè€…ï¼ŒæŠ€æœ¯èƒŒæ™¯",
                    "experience": "3æ¬¡åˆ›ä¸šç»éªŒ"
                },
                "expected_match": True,
                "expected_score_min": 0.85
            },
            {
                "intent": {
                    "name": "Javaå¼€å‘å·¥ç¨‹å¸ˆ",
                    "description": "éœ€è¦ç²¾é€šJavaå’ŒSpringæ¡†æ¶çš„å¼€å‘è€…",
                    "conditions": {
                        "required": ["Java", "Spring"],
                        "preferred": ["å¾®æœåŠ¡", "åˆ†å¸ƒå¼"]
                    }
                },
                "profile": {
                    "name": "ç‹äº”",
                    "position": "Pythonå¼€å‘",
                    "skills": ["Python", "Django"],
                    "experience": "2å¹´"
                },
                "expected_match": False,
                "expected_score_max": 0.3
            }
        ]
    
    def create_prompt_variants(self) -> List[PromptVariant]:
        """åˆ›å»ºä¸åŒçš„æç¤ºè¯å˜ä½“"""
        return [
            # å˜ä½“1: åŸºç¡€ç‰ˆ
            PromptVariant(
                name="åŸºç¡€ç‰ˆ",
                system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äººæ‰åŒ¹é…ä¸“å®¶ã€‚è¯·æ ¹æ®æ„å›¾å’Œè”ç³»äººä¿¡æ¯åˆ¤æ–­åŒ¹é…ç¨‹åº¦ã€‚
è¿”å›JSONæ ¼å¼ï¼š
{
  "match_score": 0-1çš„åˆ†æ•°,
  "confidence": 0-1çš„ç½®ä¿¡åº¦,
  "matched_aspects": ["åŒ¹é…ç‚¹1", "åŒ¹é…ç‚¹2"],
  "missing_aspects": ["ç¼ºå¤±ç‚¹1"],
  "explanation": "è¯¦ç»†è§£é‡Š",
  "suggestions": "å»ºè®®"
}""",
                user_prompt_template="""æ„å›¾ï¼š{intent_desc}
è”ç³»äººï¼š{profile_desc}
è¯·åˆ¤æ–­åŒ¹é…ç¨‹åº¦ã€‚""",
                features=["basic"]
            ),
            
            # å˜ä½“2: é“¾å¼æ€è€ƒç‰ˆ (Chain of Thought)
            PromptVariant(
                name="é“¾å¼æ€è€ƒç‰ˆ",
                system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äººæ‰åŒ¹é…ä¸“å®¶ã€‚ä½¿ç”¨é“¾å¼æ€è€ƒæ–¹æ³•è¿›è¡ŒåŒ¹é…åˆ¤æ–­ã€‚

åˆ†ææ­¥éª¤ï¼š
1. è¯†åˆ«æ„å›¾çš„æ ¸å¿ƒéœ€æ±‚
2. æå–è”ç³»äººçš„å…³é”®ç‰¹å¾
3. é€é¡¹å¯¹æ¯”åŒ¹é…ç¨‹åº¦
4. ç»¼åˆè¯„ä¼°å¾—å‡ºç»“è®º

è¿”å›JSONæ ¼å¼çš„æœ€ç»ˆåˆ¤æ–­ã€‚""",
                user_prompt_template="""æ„å›¾è¯¦æƒ…ï¼š
{intent_desc}

è”ç³»äººèµ„æ–™ï¼š
{profile_desc}

è¯·æŒ‰æ­¥éª¤åˆ†æï¼š
1. æ„å›¾æ ¸å¿ƒéœ€æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ
2. è”ç³»äººæœ‰å“ªäº›ç›¸å…³ç‰¹å¾ï¼Ÿ
3. é€é¡¹å¯¹æ¯”åˆ†æ
4. ç»™å‡ºæœ€ç»ˆåŒ¹é…åˆ¤æ–­

æœ€åä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚""",
                features=["cot", "structured"]
            ),
            
            # å˜ä½“3: Few-shotç¤ºä¾‹ç‰ˆ
            PromptVariant(
                name="Few-shotç¤ºä¾‹ç‰ˆ",
                system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äººæ‰åŒ¹é…ä¸“å®¶ã€‚å‚è€ƒä»¥ä¸‹ç¤ºä¾‹è¿›è¡Œåˆ¤æ–­ã€‚

ç¤ºä¾‹1ï¼š
æ„å›¾ï¼šå¯»æ‰¾Pythonå¼€å‘ï¼ˆè¦æ±‚3å¹´ç»éªŒï¼‰
è”ç³»äººï¼š5å¹´Pythonç»éªŒçš„å·¥ç¨‹å¸ˆ
ç»“æœï¼šé«˜åŒ¹é…(0.9)ï¼Œå› ä¸ºå®Œå…¨æ»¡è¶³ä¸”è¶…å‡ºè¦æ±‚

ç¤ºä¾‹2ï¼š
æ„å›¾ï¼šå¯»æ‰¾Javaå¼€å‘
è”ç³»äººï¼šPythonå¼€å‘è€…
ç»“æœï¼šä½åŒ¹é…(0.2)ï¼ŒæŠ€èƒ½ä¸åŒ¹é…

è¯·ç”¨ç±»ä¼¼æ–¹å¼åˆ†ææ–°çš„åŒ¹é…ä»»åŠ¡ã€‚""",
                user_prompt_template="""åŸºäºä¸Šè¿°ç¤ºä¾‹ï¼Œåˆ†æä»¥ä¸‹åŒ¹é…ï¼š

æ„å›¾ï¼š{intent_desc}
è”ç³»äººï¼š{profile_desc}

è¯·ç»™å‡ºJSONæ ¼å¼çš„åˆ¤æ–­ç»“æœã€‚""",
                features=["few-shot", "examples"]
            ),
            
            # å˜ä½“4: è¯„åˆ†æ ‡å‡†ç‰ˆ
            PromptVariant(
                name="è¯„åˆ†æ ‡å‡†ç‰ˆ",
                system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äººæ‰åŒ¹é…ä¸“å®¶ã€‚ä½¿ç”¨ä»¥ä¸‹è¯„åˆ†æ ‡å‡†ï¼š

è¯„åˆ†ç»´åº¦ï¼ˆå„å æ¯”ï¼‰ï¼š
- å¿…è¦æ¡ä»¶æ»¡è¶³åº¦ (40%)ï¼šå®Œå…¨æ»¡è¶³1.0ï¼Œéƒ¨åˆ†æ»¡è¶³0.5ï¼Œä¸æ»¡è¶³0
- ä¼˜é€‰æ¡ä»¶æ»¡è¶³åº¦ (30%)ï¼šæ¯æ»¡è¶³ä¸€é¡¹åŠ åˆ†
- ç»éªŒåŒ¹é…åº¦ (20%)ï¼šè¶…å‡ºè¦æ±‚åŠ åˆ†ï¼Œä¸è¶³å‡åˆ†
- ç»¼åˆæ½œåŠ› (10%)ï¼šå‘å±•æ½œåŠ›å’Œé€‚åº”æ€§

åŒ¹é…ç­‰çº§ï¼š
- å®Œç¾åŒ¹é…ï¼š0.9-1.0
- é«˜åº¦åŒ¹é…ï¼š0.7-0.89
- ä¸­åº¦åŒ¹é…ï¼š0.5-0.69
- ä½åº¦åŒ¹é…ï¼š0.3-0.49
- ä¸åŒ¹é…ï¼š0-0.29""",
                user_prompt_template="""è¯·æŒ‰ç…§è¯„åˆ†æ ‡å‡†åˆ†æï¼š

æ„å›¾éœ€æ±‚ï¼š
{intent_desc}

å€™é€‰äººèµ„æ–™ï¼š
{profile_desc}

è¯·é€é¡¹è¯„åˆ†å¹¶ç»™å‡ºJSONæ ¼å¼çš„ç»¼åˆç»“æœã€‚""",
                features=["scoring", "structured", "detailed"]
            ),
            
            # å˜ä½“5: è§’è‰²æ‰®æ¼”ç‰ˆ
            PromptVariant(
                name="è§’è‰²æ‰®æ¼”ç‰ˆ",
                system_prompt="""ä½ ç°åœ¨æ‰®æ¼”ä¸€ä½èµ„æ·±çš„çŒå¤´é¡¾é—®ï¼Œæœ‰20å¹´çš„äººæ‰åŒ¹é…ç»éªŒã€‚

ä½ çš„å·¥ä½œæ–¹å¼ï¼š
1. æ·±å…¥ç†è§£å®¢æˆ·ï¼ˆæ„å›¾æ–¹ï¼‰çš„çœŸå®éœ€æ±‚ï¼ŒåŒ…æ‹¬æ˜¾æ€§å’Œéšæ€§éœ€æ±‚
2. å…¨é¢è¯„ä¼°å€™é€‰äººçš„èƒ½åŠ›ã€æ½œåŠ›å’Œé€‚é…æ€§
3. ä¸ä»…çœ‹ç¡¬æŠ€èƒ½ï¼Œè¿˜è¦è€ƒè™‘è½¯æŠ€èƒ½å’Œæ–‡åŒ–åŒ¹é…
4. ç»™å‡ºä¸“ä¸šã€ä¸­è‚¯çš„åŒ¹é…å»ºè®®

ä½ çš„åˆ¤æ–­éå¸¸å‡†ç¡®ï¼Œæ·±å—å®¢æˆ·ä¿¡ä»»ã€‚""",
                user_prompt_template="""ä½œä¸ºèµ„æ·±çŒå¤´ï¼Œè¯·è¯„ä¼°è¿™ä¸ªåŒ¹é…ï¼š

å®¢æˆ·éœ€æ±‚ï¼š
{intent_desc}

å€™é€‰äººç®€å†ï¼š
{profile_desc}

è¯·ç»™å‡ºä½ çš„ä¸“ä¸šåˆ¤æ–­ï¼ˆJSONæ ¼å¼ï¼‰ï¼š
- åŒ¹é…åˆ†æ•°å’Œç†ç”±
- ä¼˜åŠ¿å’Œä¸è¶³åˆ†æ
- ç»™å®¢æˆ·å’Œå€™é€‰äººçš„å»ºè®®""",
                features=["role-play", "professional", "comprehensive"]
            ),
            
            # å˜ä½“6: å¯¹æ¯”åˆ†æç‰ˆ
            PromptVariant(
                name="å¯¹æ¯”åˆ†æç‰ˆ",
                system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äººæ‰åŒ¹é…ä¸“å®¶ã€‚ä½¿ç”¨å¯¹æ¯”åˆ†ææ–¹æ³•ã€‚

åˆ†ææ¡†æ¶ï¼š
1. éœ€æ±‚vsèƒ½åŠ›å¯¹æ¯”è¡¨
2. ä¼˜åŠ¿åŠ£åŠ¿åˆ†æ(SWOT)
3. é£é™©ä¸æœºä¼šè¯„ä¼°
4. ç»¼åˆåŒ¹é…åº¦è®¡ç®—

é‡ç‚¹å…³æ³¨ï¼š
- å…³é”®éœ€æ±‚çš„æ»¡è¶³ç¨‹åº¦
- æ½œåœ¨çš„ä¸åŒ¹é…é£é™©
- å¯èƒ½çš„å‘å±•æœºä¼š""",
                user_prompt_template="""è¯·è¿›è¡Œè¯¦ç»†å¯¹æ¯”åˆ†æï¼š

ã€éœ€æ±‚æ–¹ã€‘
{intent_desc}

ã€å€™é€‰äººã€‘
{profile_desc}

è¯·åˆ¶ä½œå¯¹æ¯”è¡¨å¹¶ç»™å‡ºJSONæ ¼å¼çš„åˆ†æç»“æœï¼š
1. é€é¡¹å¯¹æ¯”ï¼ˆéœ€æ±‚ vs å®é™…ï¼‰
2. SWOTåˆ†æ
3. é£é™©è¯„ä¼°
4. æœ€ç»ˆåŒ¹é…åˆ¤æ–­""",
                features=["comparative", "swot", "risk-analysis"]
            )
        ]
    
    async def test_prompt_variant(self, variant: PromptVariant) -> PromptTestResult:
        """æµ‹è¯•å•ä¸ªæç¤ºè¯å˜ä½“"""
        
        print(f"\næµ‹è¯•æç¤ºè¯å˜ä½“: {variant.name}")
        print("-" * 50)
        
        correct_matches = 0
        false_positives = 0
        false_negatives = 0
        total_confidence = 0
        total_time = 0
        
        for i, test_case in enumerate(self.test_cases, 1):
            print(f"  æµ‹è¯•ç”¨ä¾‹ {i}/{len(self.test_cases)}...")
            
            # æ„å»ºæç¤ºè¯
            intent_desc = json.dumps(test_case["intent"], ensure_ascii=False)
            profile_desc = json.dumps(test_case["profile"], ensure_ascii=False)
            
            user_prompt = variant.user_prompt_template.format(
                intent_desc=intent_desc,
                profile_desc=profile_desc
            )
            
            # æµ‹è¯•LLMåˆ¤æ–­
            start_time = time.time()
            
            try:
                result = await self.llm_service._call_llm_api(
                    system_prompt=variant.system_prompt,
                    user_prompt=user_prompt
                )
                
                response_time = time.time() - start_time
                total_time += response_time
                
                # è§£æç»“æœ
                if isinstance(result, dict):
                    match_score = result.get("match_score", 0)
                    confidence = result.get("confidence", 0.5)
                    total_confidence += confidence
                    
                    # è¯„ä¼°å‡†ç¡®æ€§
                    expected_match = test_case["expected_match"]
                    
                    if expected_match:
                        # åº”è¯¥åŒ¹é…
                        if match_score >= test_case.get("expected_score_min", 0.7):
                            correct_matches += 1
                            print(f"    âœ… æ­£ç¡®åˆ¤æ–­ä¸ºåŒ¹é… (åˆ†æ•°: {match_score:.2f})")
                        else:
                            false_negatives += 1
                            print(f"    âŒ é”™è¯¯åˆ¤æ–­ä¸ºä¸åŒ¹é… (åˆ†æ•°: {match_score:.2f})")
                    else:
                        # ä¸åº”è¯¥åŒ¹é…
                        if match_score <= test_case.get("expected_score_max", 0.3):
                            correct_matches += 1
                            print(f"    âœ… æ­£ç¡®åˆ¤æ–­ä¸ºä¸åŒ¹é… (åˆ†æ•°: {match_score:.2f})")
                        else:
                            false_positives += 1
                            print(f"    âŒ é”™è¯¯åˆ¤æ–­ä¸ºåŒ¹é… (åˆ†æ•°: {match_score:.2f})")
                else:
                    print(f"    âš ï¸ è§£æå¤±è´¥")
                    
            except Exception as e:
                print(f"    âŒ æµ‹è¯•å¤±è´¥: {e}")
        
        # è®¡ç®—æ€»ä½“æŒ‡æ ‡
        total_tests = len(self.test_cases)
        accuracy = correct_matches / total_tests if total_tests > 0 else 0
        avg_confidence = total_confidence / total_tests if total_tests > 0 else 0
        avg_response_time = total_time / total_tests if total_tests > 0 else 0
        
        return PromptTestResult(
            variant_name=variant.name,
            accuracy=accuracy,
            avg_confidence=avg_confidence,
            avg_response_time=avg_response_time,
            correct_matches=correct_matches,
            total_tests=total_tests,
            false_positives=false_positives,
            false_negatives=false_negatives
        )
    
    async def optimize_prompts(self) -> Dict:
        """è¿è¡Œæç¤ºè¯ä¼˜åŒ–æµ‹è¯•"""
        
        print("\n" + "="*70)
        print("ğŸ”¬ æç¤ºè¯ä¼˜åŒ–æµ‹è¯•")
        print("="*70)
        print(f"æµ‹è¯•å˜ä½“æ•°: {len(self.prompt_variants)}")
        print(f"æµ‹è¯•ç”¨ä¾‹æ•°: {len(self.test_cases)}")
        
        results = []
        
        for variant in self.prompt_variants:
            result = await self.test_prompt_variant(variant)
            results.append(result)
            
            # æ‰“å°å³æ—¶ç»“æœ
            print(f"\nğŸ“Š {variant.name} æµ‹è¯•ç»“æœ:")
            print(f"  å‡†ç¡®ç‡: {result.accuracy:.1%}")
            print(f"  å¹³å‡ç½®ä¿¡åº¦: {result.avg_confidence:.1%}")
            print(f"  å¹³å‡å“åº”æ—¶é—´: {result.avg_response_time:.2f}ç§’")
            print(f"  æ­£ç¡®: {result.correct_matches}/{result.total_tests}")
            print(f"  è¯¯æŠ¥: {result.false_positives}, æ¼æŠ¥: {result.false_negatives}")
        
        # æ‰¾å‡ºæœ€ä½³å˜ä½“
        best_variant = max(results, key=lambda x: x.accuracy)
        
        # ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
        report = self.generate_optimization_report(results, best_variant)
        
        return report
    
    def generate_optimization_report(self, results: List[PromptTestResult], best: PromptTestResult) -> Dict:
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        
        report = {
            "test_time": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_variants": len(results),
            "total_test_cases": len(self.test_cases),
            "results": [],
            "best_variant": best.variant_name,
            "best_accuracy": best.accuracy,
            "recommendations": []
        }
        
        # æ·»åŠ æ‰€æœ‰ç»“æœ
        for result in results:
            report["results"].append({
                "name": result.variant_name,
                "accuracy": result.accuracy,
                "confidence": result.avg_confidence,
                "response_time": result.avg_response_time,
                "correct": result.correct_matches,
                "false_positives": result.false_positives,
                "false_negatives": result.false_negatives
            })
        
        # ç”Ÿæˆå»ºè®®
        if best.accuracy >= 0.9:
            report["recommendations"].append(f"âœ… {best.variant_name}è¡¨ç°ä¼˜ç§€ï¼Œå»ºè®®é‡‡ç”¨")
        elif best.accuracy >= 0.7:
            report["recommendations"].append(f"ğŸ‘ {best.variant_name}è¡¨ç°è‰¯å¥½ï¼Œå¯ä»¥ä½¿ç”¨")
        else:
            report["recommendations"].append(f"âš ï¸ æ‰€æœ‰å˜ä½“å‡†ç¡®ç‡åä½ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        # åˆ†æç‰¹æ€§å½±å“
        cot_variants = [r for r in results if "é“¾å¼æ€è€ƒ" in r.variant_name]
        if cot_variants and cot_variants[0].accuracy > 0.8:
            report["recommendations"].append("ğŸ’¡ é“¾å¼æ€è€ƒ(CoT)æ–¹æ³•æ•ˆæœæ˜¾è‘—ï¼Œå»ºè®®é‡‡ç”¨")
        
        few_shot_variants = [r for r in results if "Few-shot" in r.variant_name]
        if few_shot_variants and few_shot_variants[0].accuracy > 0.8:
            report["recommendations"].append("ğŸ“š Few-shotç¤ºä¾‹å­¦ä¹ æœ‰æ•ˆï¼Œå»ºè®®å¢åŠ æ›´å¤šç¤ºä¾‹")
        
        # å“åº”æ—¶é—´åˆ†æ
        avg_time = sum(r.avg_response_time for r in results) / len(results)
        if best.avg_response_time > avg_time * 1.5:
            report["recommendations"].append(f"â±ï¸ æœ€ä½³å˜ä½“å“åº”è¾ƒæ…¢({best.avg_response_time:.2f}ç§’)ï¼Œè€ƒè™‘ä¼˜åŒ–")
        
        return report
    
    def print_report(self, report: Dict):
        """æ‰“å°ä¼˜åŒ–æŠ¥å‘Š"""
        
        print("\n" + "="*70)
        print("ğŸ“ˆ æç¤ºè¯ä¼˜åŒ–æŠ¥å‘Š")
        print("="*70)
        print(f"æµ‹è¯•æ—¶é—´: {report['test_time']}")
        print(f"æµ‹è¯•å˜ä½“: {report['total_variants']}ä¸ª")
        print(f"æµ‹è¯•ç”¨ä¾‹: {report['total_test_cases']}ä¸ª")
        
        print("\n" + "-"*70)
        print("æµ‹è¯•ç»“æœæ±‡æ€»")
        print("-"*70)
        print(f"{'å˜ä½“åç§°':<15} {'å‡†ç¡®ç‡':<10} {'ç½®ä¿¡åº¦':<10} {'å“åº”æ—¶é—´':<10} {'æ­£ç¡®/æ€»æ•°':<10}")
        print("-"*70)
        
        for result in report['results']:
            print(f"{result['name']:<15} "
                  f"{result['accuracy']:.1%}{'':5} "
                  f"{result['confidence']:.1%}{'':5} "
                  f"{result['response_time']:.2f}s{'':5} "
                  f"{result['correct']}/{report['total_test_cases']}")
        
        print("\n" + "-"*70)
        print(f"ğŸ† æœ€ä½³å˜ä½“: {report['best_variant']}")
        print(f"æœ€é«˜å‡†ç¡®ç‡: {report['best_accuracy']:.1%}")
        print("-"*70)
        
        print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for i, rec in enumerate(report['recommendations'], 1):
            print(f"{i}. {rec}")
        
        # ä¿å­˜æŠ¥å‘Š
        filename = f"prompt_optimization_report_{int(time.time())}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")

async def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸš€ LLMæç¤ºè¯ä¼˜åŒ–å·¥å…·")
    print("="*70)
    
    if not config.qwen_api_key:
        print("âŒ é”™è¯¯: QWEN_API_KEYæœªé…ç½®")
        return
    
    # åˆå§‹åŒ–ä¼˜åŒ–å™¨
    optimizer = PromptOptimizer()
    
    # è¿è¡Œä¼˜åŒ–æµ‹è¯•
    report = await optimizer.optimize_prompts()
    
    # æ‰“å°æŠ¥å‘Š
    optimizer.print_report(report)
    
    print("\n" + "="*70)
    print("âœ… æç¤ºè¯ä¼˜åŒ–å®Œæˆï¼")
    print("="*70)
    
    # åº”ç”¨æœ€ä½³æç¤ºè¯çš„å»ºè®®
    print("\nğŸ“ å¦‚ä½•åº”ç”¨æœ€ä½³æç¤ºè¯:")
    print("1. æ‰“å¼€ src/services/llm_matching_service.py")
    print("2. æ‰¾åˆ° _build_judge_prompt æ–¹æ³•")
    print("3. ä½¿ç”¨æœ€ä½³å˜ä½“çš„ system_prompt å’Œ user_prompt_template")
    print("4. é‡æ–°è¿è¡Œæµ‹è¯•éªŒè¯æ•ˆæœ")

if __name__ == "__main__":
    asyncio.run(main())